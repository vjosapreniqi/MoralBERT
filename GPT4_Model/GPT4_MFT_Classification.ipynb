{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T08lMB1pYdet"
   },
   "source": [
    "# GPT-4 Zero-Shot Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uJvxUvaiXMow",
    "outputId": "330b7bb7-8e92-4b9c-a44c-416a8e9a4c02"
   },
   "outputs": [],
   "source": [
    "# !pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20% for the Social Media Data for GPT Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = pd.read_csv(\"path/to/test_data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "domain\n",
       "0    3384\n",
       "1    2793\n",
       "2    1509\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset.domain.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fyhwkeDAY4kn"
   },
   "source": [
    "# Define Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xbBqW2xsZDoQ"
   },
   "source": [
    "### GPT version used for generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "1hFUOhWGZG8l"
   },
   "outputs": [],
   "source": [
    "gpt_version = \"gpt-4-0125-preview\" # change to this for use GPT3 \"gpt-3.5-turbo-0125\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E1cFOpa_Zs_X"
   },
   "source": [
    "### Pricing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "4CTRm2b6Z3GZ"
   },
   "outputs": [],
   "source": [
    "pricings = {\"gpt-4-0125-preview\":(10,30),\n",
    "            \"gpt-3.5-turbo-0125\": (0.50, 1.50)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IDaw-5Mwaq4C"
   },
   "source": [
    "### Max Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "8wGM3_tGasdI"
   },
   "outputs": [],
   "source": [
    "max_tokens = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lfsi7PpWg03f"
   },
   "source": [
    "### Moral Values and their Descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "c4iAPl7bg45Q"
   },
   "outputs": [],
   "source": [
    "moral_values = {\"Care\": \"underlies the virtues of kindness and nurturance, empathy and compassion towards other people\",\n",
    "                \"Harm\": \"which represents the opposite of care, characterised by violent actions and intentions\",\n",
    "                \"Fairness\": \" which underlies the virtues of honesty, fair treatment, justice, and dependability.\",\n",
    "                \"Cheating\": \"which represents the opposite of fairness, encapsulating instances of unfairness and injustice.\",\n",
    "                \"Loyalty\": \"which deals with group loyalty, self-sacrifice, and vigilance against betrayal\",\n",
    "                \"Betrayal\":  \"which underlies wrongdoing and betraying your group or your relationship.\",\n",
    "                \"Authority\": \"which underlies virtues of leadership and respect within hierarchical relationships\",\n",
    "                \"Subversion\": \"which refers to acts of defiance against authority or hierarchy, and  rebellion against control\",\n",
    "                \"Purity\": \" which is concerned with the sanctity of the body and spirit, promoting virtues like chastity and self-restraint\",\n",
    "                \"Degradation\": \"that denotes the violation of purity and sanctity, including both physical and emotional corruption\",\n",
    "                \"Liberty\":\" which relates to the individual's need to be their own master and to avoid the dominant social mores imposed by the group\",\n",
    "                \"Oppression\": \"that underlies the violation of independence and autonomy, related to unjust treatment.\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "e4xMlqF-sF87"
   },
   "outputs": [],
   "source": [
    "all_moral_values = []\n",
    "for values in moral_values:\n",
    "  all_moral_values.append(values)\n",
    "  possible_moral_values = all_moral_values.copy()\n",
    "all_moral_values = [[value] for value in all_moral_values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(possible_moral_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Care'],\n",
       " ['Harm'],\n",
       " ['Fairness'],\n",
       " ['Cheating'],\n",
       " ['Loyalty'],\n",
       " ['Betrayal'],\n",
       " ['Authority'],\n",
       " ['Subversion'],\n",
       " ['Purity'],\n",
       " ['Degradation'],\n",
       " ['Liberty'],\n",
       " ['Oppression']]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_moral_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wh1bbHxbpTfK"
   },
   "source": [
    "### OpenAI API Key\n",
    "Here, insert the API key for OpenAI. You need to create an account and add credit to it in order to use the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "rBYhUn6kpdq-"
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "openai.api_key = \" \""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QwFdImKeYiTJ"
   },
   "source": [
    "# Utility Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WYMWIMkxYk2q"
   },
   "source": [
    "#### compute number of tokens and pricing (pricing is per 1000 token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LJollw33YrVZ",
    "outputId": "bf2f4f81-b273-4d37-c3cb-acfb46f67ae4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "def num_tokens_from_string(string: str, encoding_name: str) -> int:\n",
    "    encoding = tiktoken.encoding_for_model(encoding_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens\n",
    "\n",
    "print(num_tokens_from_string(\"Hello world, let's test tiktoken.\", gpt_version))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "fEZ1s75yzgNh"
   },
   "outputs": [],
   "source": [
    "def compute_actual_price(completion, gpt_version: str) -> int:\n",
    "    \"\"\"\n",
    "    Compute maximum price for API call with given prompt\n",
    "    The maximum price is computed by assuming the model will output\n",
    "    the maximum number of tokens that it can output (i.e. 4096).\n",
    "    Return price in dollars\n",
    "    \"\"\"\n",
    "    price_in = completion.usage.prompt_tokens/1000000*pricings[gpt_version][0]\n",
    "    price_out = completion.usage.completion_tokens/1000000*pricings[gpt_version][1]\n",
    "\n",
    "    return price_in+price_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B-pUdM5RioMi"
   },
   "source": [
    "#### Accessing Moral Values Descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "8PvUuu7liqjP"
   },
   "outputs": [],
   "source": [
    "def get_moral_value(moral_value):\n",
    "  for key, description in moral_values.items():\n",
    "    if moral_value in key:\n",
    "      return description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0LKB1BWh2TCE"
   },
   "source": [
    "### Vectorise Moral Values\n",
    "Create vector representation of moral values to store results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "ohHkdWEH2aO0"
   },
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "def vectorise_moral_values(moral_values: List[int], possible_moral_values):\n",
    "  moral_values_vector = [0 for _ in range(len(possible_moral_values))]\n",
    "  for value in moral_values:\n",
    "    moral_values_vector[value] = 1\n",
    "  return moral_values_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lO_0-CRo3MH6",
    "outputId": "79279a65-98a6-4370-c564-8c18c2da977e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorise_moral_values([0, 6], possible_moral_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tyn5TKDfbtCD"
   },
   "source": [
    "### Prompt Creation and Response Formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JSON_QueryHandler:\n",
    "    def __init__(self, model, print_output=False):\n",
    "        self.print_output = print_output\n",
    "        self.model = model\n",
    "\n",
    "    def check_response_valid(self, model_response: str):\n",
    "        if not model_response.strip():\n",
    "            print(\"Empty model response.\")\n",
    "            return False, None\n",
    "        \n",
    "        valid = True\n",
    "\n",
    "        try:\n",
    "            chat_completion_json = json.loads(model_response)\n",
    "        except json.JSONDecodeError:\n",
    "            print(\"Model response: \" + str(model_response)[0:50] + \"...\")\n",
    "            print(\"Could not cast model response to JSON. Retrying by trimming ends.\")\n",
    "            try:\n",
    "                model_response_trimmed = \"[\" + model_response.split(\"[\", 1)[1]\n",
    "                model_response_trimmed = model_response_trimmed.split(\"]\", 1)[0] + \"]\"\n",
    "                chat_completion_json = json.loads(model_response_trimmed)\n",
    "            except (json.JSONDecodeError, IndexError) as e:\n",
    "                print(f\"Still could not cast model response to JSON. Error: {str(e)}\")\n",
    "                return False, self.create_cast_to_json_prompt(model_response)\n",
    "\n",
    "        try:\n",
    "            moral_values = chat_completion_json[\"moral_values\"]\n",
    "            for value in moral_values:\n",
    "                if value not in set(list(range(12))):\n",
    "                    print(f\"Prediction index {value} out of possible moral value keys.\")\n",
    "                    valid = False\n",
    "        except (TypeError, KeyError) as e:\n",
    "            print(f\"TypeError or KeyError encountered: {str(e)}\")\n",
    "            try:\n",
    "                for value in chat_completion_json:\n",
    "                    if value not in set(list(range(12))):\n",
    "                        print(f\"Prediction index {value} out of possible moral value keys.\")\n",
    "                        valid = False\n",
    "                if valid:\n",
    "                    chat_completion_json[\"moral_values\"] = chat_completion_json\n",
    "            except (TypeError, KeyError) as e:\n",
    "                print(f\"TypeError or KeyError encountered: {str(e)}\")\n",
    "                try:\n",
    "                    moral_values = list(chat_completion_json.values())[0]\n",
    "                    for value in moral_values:\n",
    "                        if value not in set(list(range(12))):\n",
    "                            print(f\"Prediction index {value} out of possible moral value keys.\")\n",
    "                            valid = False\n",
    "                    if valid:\n",
    "                        chat_completion_json[\"moral_values\"] = moral_values\n",
    "                except Exception as e:\n",
    "                    print(f\"Exception encountered while processing JSON: {str(e)}\")\n",
    "                    valid = False\n",
    "\n",
    "        if valid:\n",
    "            return valid, chat_completion_json\n",
    "        else:\n",
    "            return valid, self.create_cast_to_json_prompt(model_response)\n",
    "\n",
    "    def create_cast_to_json_prompt(self, model_response: str):\n",
    "        system_template = \"\"\"\n",
    "You are a JSON writing assistant. \n",
    "When given invalid JSON, you correct it. \n",
    "If JSON is already valid, return it as it is.\n",
    "\"\"\"\n",
    "        system_message_prompt = system_template\n",
    "        human_prompt = f\"Invalid JSON: \\n{model_response} \\n\\nCorrected JSON:\\n\"\n",
    "        prompt = [\n",
    "            {\"role\": \"system\", \"content\": system_message_prompt},\n",
    "            {\"role\": \"user\", \"content\": human_prompt},\n",
    "        ]\n",
    "\n",
    "        return prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "id": "y22vByQMbyEU"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def prompt_creation(sm_post,\n",
    "                    gpt_version,\n",
    "                    option=2,\n",
    "                    CoT=False):\n",
    "\n",
    "  if CoT:\n",
    "    ending = \"\\n\\nLet's think it step by step and output your reasoning together with the json results.\"\n",
    "  else:\n",
    "    ending = \"\\n\\nDO NOT explain your reasoning.\\nDO NOT output anything else but the json results.\"\n",
    "  if not option:\n",
    "      system_message = \"\"\"\n",
    "                    You will be provided with Social media posts \n",
    "                    regarding different social topics. \\\n",
    "                    The Social media posts will be delimited with \\\n",
    "                    #### characters.\n",
    "                    Classify each social media post into 12 Possible Moral Values \\\n",
    "                    as defined in Moral Foundation Theory.\n",
    "\n",
    "                    The availablle Moral Values are: \\\n",
    "                    0: care \\\n",
    "                    1: harm \\\n",
    "                    2: fairness \\\n",
    "                    3: cheating \\\n",
    "                    4: loyalty \\\n",
    "                    5: betrayal \\\n",
    "                    6: authority \\\n",
    "                    7: subversion \\\n",
    "                    8: purity \\\n",
    "                    9: degradation\\\n",
    "                    10: liberty\\\n",
    "                    11: oppression\n",
    "\n",
    "                    Report the results in json format such that the key of the\n",
    "                    correct moral values is reported in a list:\n",
    "                    e.g. {\"moral_values\":[0]}\n",
    "                    \"\"\"\n",
    "  elif option<3:\n",
    "      system_message = \"\"\"\n",
    "                    You will be provided with Social media posts \n",
    "                    regarding different social topics. \\\n",
    "                    The Social media posts will be delimited with \\\n",
    "                    #### characters.\n",
    "                    Classify each social media post into 12 Possible Moral Values \\\n",
    "                    as defined in Moral Foundation Theory.\n",
    "\n",
    "                    The availablle Moral Values are: \\\n",
    "                    0: care \\\n",
    "                    1: harm \\\n",
    "                    2: fairness \\\n",
    "                    3: cheating \\\n",
    "                    4: loyalty \\\n",
    "                    5: betrayal \\\n",
    "                    6: authority \\\n",
    "                    7: subversion \\\n",
    "                    8: purity \\\n",
    "                    9: degradation\\\n",
    "                    10: liberty\\\n",
    "                    11: oppression\n",
    "\n",
    "                    This is a multilabel classification problem: more than\n",
    "                    one category at a time can be assigned.\n",
    "                    Report the results in json format such that the keys of the\n",
    "                    correct moral values are reported in a list:\n",
    "                    e.g. {\"moral_values\":[0,2]}\n",
    "                    \"\"\"\n",
    "  else:\n",
    "    system_message = \"\"\"\n",
    "                   You will be provided with Social media posts\n",
    "                    regarding different social topics. \\\n",
    "                    The Social media posts will be delimited with \\\n",
    "                    #### characters.\n",
    "                    Classify each social media post into 12 Possible Moral Values \\\n",
    "                    as defined in Moral Foundation Theory.\n",
    "\n",
    "                    The availablle Moral Foundations are: \\\n",
    "                    0: care \\\n",
    "                    1: harm \\\n",
    "                    2: fairness \\\n",
    "                    3: cheating \\\n",
    "                    4: loyalty \\\n",
    "                    5: betrayal \\\n",
    "                    6: authority \\\n",
    "                    7: subversion \\\n",
    "                    8: purity \\\n",
    "                    9: degradation\\\n",
    "                    10: liberty\\\n",
    "                    11: oppression\n",
    "\n",
    "                    The explanation of the moral foundations is as following:\n",
    "                    Care: underlies the virtues of kindness, nurturance, empathy, and compassion towards others. \n",
    "                    Harm: represents the opposite of care, characterized by violent actions and intentions. \n",
    "                    Fairness: underlies virtues of honesty, fair treatment, justice, and dependability. \n",
    "                    Cheating: represents the opposite of fairness, encapsulating instances of unfairness and injustice. \n",
    "                    Loyalty: represents group loyalty, self-sacrifice, and vigilance against betrayal. \n",
    "                    Betrayal: represents the opposite of loyalty and underlies wrongdoing and betraying your group or your relationship. \n",
    "                    Authority: underlies virtues of leadership and respect within hierarchical relationships.\n",
    "                    Subversion: represents the opposite of authority, referring to acts of defiance against hierarchy or tradition and rebellion against control. \n",
    "                    Purity: is concerned with the sanctity of the body and spirit, promoting virtues like chastity and self-restraint. \n",
    "                    Degradation: represents the opposite of purity, denoting the violation of sanctity, including both physical and emotional corruption.\n",
    "                    Liberty: is related to the individual's need to be their own master and to avoid the dominant social mores imposed by the group.\n",
    "                    Oppression: underlies the violation of independence and autonomy, related to unjust treatment.\n",
    "                    \n",
    "                    \n",
    "                    This is a multilabel classification problem: where it's possible to assign one or multiple moral categories simultaneously.\n",
    "                    It's important to consider the moral foundations and their opposing polarities.\n",
    "                    (Care versus Harm, Fairness versus Cheating, and Purity versus Degradation, and so on). \n",
    "                    Typically, the Social media posts can be interpreted through either a positive (e.g. Loyalty) or negative (e.g. Betrayal) moral foundation, but not both opposites at the same time. \n",
    "                    Report the results in json format such that the keys of the\n",
    "                    correct moral values are reported in a list:\n",
    "                    e.g. {\"moral_values\":[0,2]}\n",
    "                    \"\"\"\n",
    "\n",
    "  system_message += ending\n",
    "\n",
    "  if not option:\n",
    "    # option 0 does not include any role and it is single label\n",
    "    prompt = [{\"role\": \"system\", \"content\": system_message},\n",
    "              {\"role\": \"user\", \"content\": f\"####{sm_post}####\"}]\n",
    "  elif option==1:\n",
    "    # option 1 does not include any role assignment or moral value explanation\n",
    "    prompt = [{\"role\": \"system\", \"content\": system_message},\n",
    "              {\"role\": \"user\", \"content\": f\"####{sm_post}####\"}]\n",
    "  elif option==2:\n",
    "    # option 1 does include role assignment but no moral value explanation\n",
    "    system_message = f\"You are an assistant to a researcher studying social psychology. {system_message}\"\n",
    "    prompt = [{\"role\": \"system\", \"content\": system_message},\n",
    "              {\"role\": \"user\", \"content\": f\"####{sm_post}####\"}]\n",
    "  elif option==3:\n",
    "    # option 2 does not include role assignment. Include moral value explanation\n",
    "    prompt = [{\"role\": \"system\", \"content\": system_message},\n",
    "              {\"role\": \"user\", \"content\": f\"####{sm_post}####\"}]\n",
    "  elif option==4:\n",
    "    # option 3 does include role assignment and moral value explanation\n",
    "    system_message = f\"You are an assistant to a researcher studying social psychology. {system_message}\"\n",
    "    prompt = [{\"role\": \"system\", \"content\": system_message},\n",
    "              {\"role\": \"user\", \"content\": f\"####{sm_post}####\"}]\n",
    "\n",
    "  return prompt\n",
    "\n",
    "def clean_completion(completion):\n",
    "   return re.sub(\"\\n\\(.*?\\)\\n\", \"\", completion)\n",
    "\n",
    "def get_completion(sm_post,\n",
    "                   model,\n",
    "                   query_handler=None,\n",
    "                   temperature=0,\n",
    "                   prompt_option=0,\n",
    "                   CoT=False):\n",
    "\n",
    "  prompt = prompt_creation(sm_post, gpt_version=model, option=prompt_option, CoT=CoT)\n",
    "\n",
    "  response = openai.chat.completions.create(\n",
    "\n",
    "  model=model,\n",
    "\n",
    "  messages=prompt,\n",
    "\n",
    "  temperature=temperature,\n",
    "\n",
    "  )\n",
    "\n",
    "  answer = response.choices[0].message.content\n",
    "\n",
    "  if CoT:\n",
    "    results = re.findall(\"\\{[\\n]?.*?[\\n]?\\}\", answer)\n",
    "    if 0<len(results)<2:\n",
    "      json_answer = results[0]\n",
    "    else:\n",
    "      actual_price = compute_actual_price(response, model)\n",
    "      response = \"FAILED\"\n",
    "      return response, actual_price, answer\n",
    "  else:\n",
    "    json_answer = answer\n",
    "\n",
    "  actual_price = compute_actual_price(response, model)\n",
    "\n",
    "  if query_handler is not None:\n",
    "    valid, response = query_handler.check_response_valid(json_answer)\n",
    "    if not valid:\n",
    "      response = openai.chat.completions.create(\n",
    "\n",
    "                model=model,\n",
    "\n",
    "                messages=response,\n",
    "\n",
    "                temperature=temperature,\n",
    "\n",
    "                )\n",
    "\n",
    "      actual_price += compute_actual_price(response, model)\n",
    "\n",
    "      valid, response = query_handler.check_response_valid(response.choices[0].message.content)\n",
    "\n",
    "      if not valid:\n",
    "        response = \"FAILED\"\n",
    "\n",
    "  return response, actual_price, answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WjaSj5c8potV"
   },
   "source": [
    "# Main Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "id": "7Qa2oT3frAix"
   },
   "outputs": [],
   "source": [
    "prompt_option = 4 # use both role assignment and moral value description, define artisti to mimic rather than genre more generally\n",
    "temperature = 0 # increase for more creative outputs, decrease for more deterministic ones\n",
    "CoT = True # this option makes the prompt a Chain of Thought, therefore outputting the reasoning of the model together with the answer (and possibly improving results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_progress(index, sm_text,results, answers,  filename='gpt_cls_progress.pkl'):\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump((index, sm_text, results, answers), f)\n",
    "\n",
    "def load_progress(filename='gpt_cls_progress.pkl'):\n",
    "    try:\n",
    "        with open(filename, 'rb') as f:\n",
    "            return pickle.load(f)\n",
    "    except FileNotFoundError:\n",
    "        return [], []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start runing the GPT model for classification task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Sgopc6xBpqrx",
    "outputId": "c31c4fe0-b339-442c-d1f4-3f8645502fe8"
   },
   "outputs": [],
   "source": [
    "running_price = 0\n",
    "results = []\n",
    "answers = []\n",
    "sm_text = []\n",
    "index = []\n",
    "for idx, sm_post in enumerate(df.cleaned_text):\n",
    "    query_handler = JSON_QueryHandler(gpt_version, print_output=True)\n",
    "    \n",
    "    result, price, answer = get_completion(sm_post,\n",
    "                                         gpt_version,\n",
    "                                         query_handler,\n",
    "                                         temperature,\n",
    "                                         prompt_option,\n",
    "                                         CoT\n",
    "                                        )\n",
    "    running_price += price\n",
    "    answers.append(answer)\n",
    "    index.append(idx)\n",
    "    sm_text.append(df.cleaned_text[idx])  \n",
    "    try:\n",
    "        results.append(vectorise_moral_values(result[\"moral_values\"], possible_moral_values))\n",
    "    except TypeError:\n",
    "        results.append([0 for _ in range(len(possible_moral_values))])\n",
    "    if not idx%10:\n",
    "        print(f\"Running price: {running_price}\")\n",
    "        save_progress(index, sm_text, results, answers)\n",
    "\n",
    "# Save final progress\n",
    "save_progress(index, sm_text, results, answers)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "id": "4-oehjIBqIj3"
   },
   "outputs": [],
   "source": [
    "result_df = {value:[] for value in possible_moral_values}\n",
    "result_df[\"LLM-answer\"] = answers\n",
    "\n",
    "for result in results:\n",
    "  for is_there, value in zip(result, possible_moral_values):\n",
    "    result_df[value].append(is_there)\n",
    "\n",
    "result_df = pd.DataFrame(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_human_annotators = pd.concat([df, result_df], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the classification results:\n",
    "GPT_human_annotators.to_csv('../path/to/saved/csv_file/',\n",
    "                                          index = None)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
