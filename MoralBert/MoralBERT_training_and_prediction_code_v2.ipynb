{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9t0gtywMWlP"
      },
      "source": [
        "# Predicting Moral Values From Social Media Discourse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "AeNH-bKTLyas"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import re\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from itertools import product\n",
        "from scipy.special import softmax\n",
        "from sklearn.metrics import (accuracy_score, classification_report, f1_score,\n",
        "                             multilabel_confusion_matrix as mcm, precision_score,\n",
        "                             recall_score)\n",
        "from sklearn.model_selection import KFold, StratifiedKFold, train_test_split\n",
        "from sklearn.utils import resample\n",
        "from sklearn.utils.class_weight import compute_class_weight, compute_sample_weight\n",
        "from tabulate import tabulate\n",
        "from torch.autograd import Function\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "from torch.utils.data import (DataLoader, RandomSampler, SequentialSampler,\n",
        "                              TensorDataset)\n",
        "from tqdm import trange\n",
        "from tqdm.auto import trange\n",
        "from transformers import (AutoModel, AutoModelForSequenceClassification,\n",
        "                          AutoTokenizer, BertModel, get_linear_schedule_with_warmup)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sat Jun 15 15:43:39 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.86.10              Driver Version: 535.86.10    CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  NVIDIA A100-PCIE-40GB          On  | 00000000:86:00.0 Off |                    0 |\n",
            "| N/A   31C    P0              33W / 250W |      7MiB / 40960MiB |      0%      Default |\n",
            "|                                         |                      |             Disabled |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nnh6qmE4gNIX"
      },
      "source": [
        "## Define Base Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "rDgs1juIgOxC"
      },
      "outputs": [],
      "source": [
        "# base_model = \"allenai/longformer-base-4096\"\n",
        "base_model = \"bert-base-uncased\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8zKqgjIlLyaw"
      },
      "source": [
        "###\u00a0Datasets:\n",
        "- These are the datasets retreived from different sources. Keep in mind that due to different cleaning, pre-processing, you might have different data sizes. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9AtNuqjLyay"
      },
      "source": [
        "#### Twitter:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Yzf7BBIeLyay"
      },
      "outputs": [],
      "source": [
        "# Download the corpus here: https://osf.io/k5n7y/ \n",
        "# Concatenate all the subsets and use one-hot-encoding for multi-label mft annotations\n",
        "mftc_df = pd.read_csv('path/to/downloaded/MFTC')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "NmtoF2LyLyaz"
      },
      "outputs": [],
      "source": [
        "# General domain:\n",
        "mftc_df['domain'] = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 522
        },
        "id": "XsY2iXi9Lyaz",
        "outputId": "3b50b49b-8888-47a2-9a03-b80f4752bc80"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>cleaned_text</th>\n",
              "      <th>annotations</th>\n",
              "      <th>new_label</th>\n",
              "      <th>subdomain</th>\n",
              "      <th>care</th>\n",
              "      <th>harm</th>\n",
              "      <th>fairness</th>\n",
              "      <th>cheating</th>\n",
              "      <th>loyalty</th>\n",
              "      <th>betrayal</th>\n",
              "      <th>authority</th>\n",
              "      <th>subversion</th>\n",
              "      <th>purity</th>\n",
              "      <th>degradation</th>\n",
              "      <th>domain</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The courage to be impatient with evil and pati...</td>\n",
              "      <td>The courage to be impatient with evil and pati...</td>\n",
              "      <td>[{'annotation': 'fairness', 'annotator': 'anno...</td>\n",
              "      <td>fairness</td>\n",
              "      <td>BLM</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>#NotAllCops but OMFG already. \ud83d\ude21 Protect and se...</td>\n",
              "      <td>but OMFG already. enraged_face Protect and ser...</td>\n",
              "      <td>[{'annotation': 'care', 'annotator': 'annotato...</td>\n",
              "      <td>harm</td>\n",
              "      <td>BLM</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>stop shaving, it's your manly dignity #blackje...</td>\n",
              "      <td>stop shaving, it's your manly dignity</td>\n",
              "      <td>[{'annotation': 'nm', 'annotator': 'annotator0...</td>\n",
              "      <td>nm</td>\n",
              "      <td>BLM</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ARABS MORTAL HATRED AND ENSLAVEMENT OF THE BLA...</td>\n",
              "      <td>ARABS MORTAL HATRED AND ENSLAVEMENT OF THE BLA...</td>\n",
              "      <td>[{'annotation': 'harm,cheating', 'annotator': ...</td>\n",
              "      <td>harm</td>\n",
              "      <td>BLM</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\u201c@Babbsgirl2: #SheriffDavidClarke is my hero! ...</td>\n",
              "      <td>@user: is my hero! @user True patriot</td>\n",
              "      <td>[{'annotation': 'nm', 'annotator': 'annotator0...</td>\n",
              "      <td>nm</td>\n",
              "      <td>BLM</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  \\\n",
              "0  The courage to be impatient with evil and pati...   \n",
              "1  #NotAllCops but OMFG already. \ud83d\ude21 Protect and se...   \n",
              "2  stop shaving, it's your manly dignity #blackje...   \n",
              "3  ARABS MORTAL HATRED AND ENSLAVEMENT OF THE BLA...   \n",
              "4  \u201c@Babbsgirl2: #SheriffDavidClarke is my hero! ...   \n",
              "\n",
              "                                        cleaned_text  \\\n",
              "0  The courage to be impatient with evil and pati...   \n",
              "1  but OMFG already. enraged_face Protect and ser...   \n",
              "2              stop shaving, it's your manly dignity   \n",
              "3  ARABS MORTAL HATRED AND ENSLAVEMENT OF THE BLA...   \n",
              "4              @user: is my hero! @user True patriot   \n",
              "\n",
              "                                         annotations new_label subdomain  \\\n",
              "0  [{'annotation': 'fairness', 'annotator': 'anno...  fairness       BLM   \n",
              "1  [{'annotation': 'care', 'annotator': 'annotato...      harm       BLM   \n",
              "2  [{'annotation': 'nm', 'annotator': 'annotator0...        nm       BLM   \n",
              "3  [{'annotation': 'harm,cheating', 'annotator': ...      harm       BLM   \n",
              "4  [{'annotation': 'nm', 'annotator': 'annotator0...        nm       BLM   \n",
              "\n",
              "   care  harm  fairness  cheating  loyalty  betrayal  authority  subversion  \\\n",
              "0   0.0   0.0       1.0       0.0      0.0       0.0        0.0         0.0   \n",
              "1   0.0   1.0       0.0       0.0      0.0       0.0        0.0         0.0   \n",
              "2   0.0   0.0       0.0       0.0      0.0       0.0        0.0         0.0   \n",
              "3   0.0   1.0       0.0       0.0      0.0       0.0        0.0         0.0   \n",
              "4   0.0   0.0       0.0       0.0      0.0       0.0        0.0         0.0   \n",
              "\n",
              "   purity  degradation  domain  \n",
              "0     0.0          0.0       0  \n",
              "1     0.0          0.0       0  \n",
              "2     0.0          0.0       0  \n",
              "3     0.0          0.0       0  \n",
              "4     0.0          0.0       0  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mftc_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "subdomain\n",
              "BLM          4304\n",
              "Elections    4139\n",
              "Baltimore    3602\n",
              "Sandy        3186\n",
              "Davidson     2725\n",
              "ALM          2665\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mftc_df.subdomain.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "OoX9Fo8drCmS"
      },
      "outputs": [],
      "source": [
        "mftc_df['non-moral'] = mftc_df['new_label'].apply(lambda x: 1 if x == 'nm' else 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(20628, 17)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mftc_df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7SXykH58Lya0"
      },
      "source": [
        "#### Reddit:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "0IroIampLya0"
      },
      "outputs": [],
      "source": [
        "# Download the corpus here:https://huggingface.co/datasets/USC-MOLA-Lab/MFRC\n",
        "# Use one-hot-encoding for multi-label mft annotations\n",
        "mfrc_df = pd.read_csv('path/to/downloaded/MFRC')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VjBQx8w3rCmV",
        "outputId": "9dc7637e-6f9c-4eb0-bdec-d06b81d0471a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(17741, 24)"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mfrc_df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0TiUz9Z7Lya0"
      },
      "source": [
        "#### Let's also add the general domain:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "SOK5KJguLya1"
      },
      "outputs": [],
      "source": [
        "mfrc_df['domain'] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 568
        },
        "id": "1ZyN6ECoLya1",
        "outputId": "14bf2915-93d3-4d66-f5e0-ef928ca35e35"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>cleaned_text</th>\n",
              "      <th>subdomain</th>\n",
              "      <th>bucket</th>\n",
              "      <th>annotation</th>\n",
              "      <th>final_annotation</th>\n",
              "      <th>care</th>\n",
              "      <th>fairness</th>\n",
              "      <th>loyalty</th>\n",
              "      <th>authority</th>\n",
              "      <th>...</th>\n",
              "      <th>degradation</th>\n",
              "      <th>equality</th>\n",
              "      <th>proportionality</th>\n",
              "      <th>thin morality</th>\n",
              "      <th>non-moral</th>\n",
              "      <th>inconclusive</th>\n",
              "      <th>vader_neg</th>\n",
              "      <th>vader_neu</th>\n",
              "      <th>vader_pos</th>\n",
              "      <th>domain</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>That particular part of the debate is especial...</td>\n",
              "      <td>That particular part of the debate is especial...</td>\n",
              "      <td>europe</td>\n",
              "      <td>French politics</td>\n",
              "      <td>{'annotator03': {'annotation': 'Non-Moral', 'c...</td>\n",
              "      <td>inconclusive</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.169</td>\n",
              "      <td>0.725</td>\n",
              "      <td>0.106</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/r/france is pretty lively, with it's own ling...</td>\n",
              "      <td>/r/france is pretty lively, with it's own ling...</td>\n",
              "      <td>europe</td>\n",
              "      <td>French politics</td>\n",
              "      <td>{'annotator03': {'annotation': 'Non-Moral', 'c...</td>\n",
              "      <td>Non-Moral</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.142</td>\n",
              "      <td>0.679</td>\n",
              "      <td>0.180</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>TBH Marion Le Pen would be better. Closet fasc...</td>\n",
              "      <td>TBH Marion Le Pen would be better. Closet fasc...</td>\n",
              "      <td>neoliberal</td>\n",
              "      <td>French politics</td>\n",
              "      <td>{'annotator03': {'annotation': 'Non-Moral', 'c...</td>\n",
              "      <td>inconclusive</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.358</td>\n",
              "      <td>0.498</td>\n",
              "      <td>0.144</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>it really is a very unusual situation isn't it...</td>\n",
              "      <td>it really is a very unusual situation isn't it...</td>\n",
              "      <td>europe</td>\n",
              "      <td>French politics</td>\n",
              "      <td>{'annotator03': {'annotation': 'Non-Moral', 'c...</td>\n",
              "      <td>Non-Moral</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.118</td>\n",
              "      <td>0.772</td>\n",
              "      <td>0.110</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The Le Pen brand of conservatism and classical...</td>\n",
              "      <td>The Le Pen brand of conservatism and classical...</td>\n",
              "      <td>europe</td>\n",
              "      <td>French politics</td>\n",
              "      <td>{'annotator03': {'annotation': 'Authority', 'c...</td>\n",
              "      <td>inconclusive</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.795</td>\n",
              "      <td>0.205</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows \u00d7 25 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  \\\n",
              "0  That particular part of the debate is especial...   \n",
              "1  /r/france is pretty lively, with it's own ling...   \n",
              "2  TBH Marion Le Pen would be better. Closet fasc...   \n",
              "3  it really is a very unusual situation isn't it...   \n",
              "4  The Le Pen brand of conservatism and classical...   \n",
              "\n",
              "                                        cleaned_text   subdomain  \\\n",
              "0  That particular part of the debate is especial...      europe   \n",
              "1  /r/france is pretty lively, with it's own ling...      europe   \n",
              "2  TBH Marion Le Pen would be better. Closet fasc...  neoliberal   \n",
              "3  it really is a very unusual situation isn't it...      europe   \n",
              "4  The Le Pen brand of conservatism and classical...      europe   \n",
              "\n",
              "            bucket                                         annotation  \\\n",
              "0  French politics  {'annotator03': {'annotation': 'Non-Moral', 'c...   \n",
              "1  French politics  {'annotator03': {'annotation': 'Non-Moral', 'c...   \n",
              "2  French politics  {'annotator03': {'annotation': 'Non-Moral', 'c...   \n",
              "3  French politics  {'annotator03': {'annotation': 'Non-Moral', 'c...   \n",
              "4  French politics  {'annotator03': {'annotation': 'Authority', 'c...   \n",
              "\n",
              "  final_annotation  care  fairness  loyalty  authority  ...  degradation  \\\n",
              "0     inconclusive     0         0        0          0  ...            0   \n",
              "1        Non-Moral     0         0        0          0  ...            0   \n",
              "2     inconclusive     0         0        0          0  ...            0   \n",
              "3        Non-Moral     0         0        0          0  ...            0   \n",
              "4     inconclusive     0         0        0          0  ...            0   \n",
              "\n",
              "   equality  proportionality  thin morality  non-moral  inconclusive  \\\n",
              "0         0                0              0          0             1   \n",
              "1         0                0              0          1             0   \n",
              "2         0                0              0          0             1   \n",
              "3         0                0              0          1             0   \n",
              "4         0                0              0          0             1   \n",
              "\n",
              "   vader_neg  vader_neu  vader_pos  domain  \n",
              "0      0.169      0.725      0.106       1  \n",
              "1      0.142      0.679      0.180       1  \n",
              "2      0.358      0.498      0.144       1  \n",
              "3      0.118      0.772      0.110       1  \n",
              "4      0.000      0.795      0.205       1  \n",
              "\n",
              "[5 rows x 25 columns]"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mfrc_df.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "_fYpZAYOrCmW"
      },
      "outputs": [],
      "source": [
        "mfrc_df = mfrc_df[~mfrc_df['final_annotation'].isin(['inconclusive', 'Thin Morality'])]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "subdomain\n",
              "europe                 2050\n",
              "worldnews              1960\n",
              "Conservative           1482\n",
              "antiwork               1424\n",
              "politics               1368\n",
              "neoliberal             1346\n",
              "nostalgia              1206\n",
              "relationship_advice    1043\n",
              "AmItheAsshole          1011\n",
              "confession             1006\n",
              "geopolitics              99\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mfrc_df.subdomain.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>cleaned_text</th>\n",
              "      <th>annotation</th>\n",
              "      <th>final_annotation</th>\n",
              "      <th>care</th>\n",
              "      <th>fairness</th>\n",
              "      <th>loyalty</th>\n",
              "      <th>authority</th>\n",
              "      <th>purity</th>\n",
              "      <th>harm</th>\n",
              "      <th>...</th>\n",
              "      <th>degradation</th>\n",
              "      <th>equality</th>\n",
              "      <th>proportionality</th>\n",
              "      <th>thin morality</th>\n",
              "      <th>non-moral</th>\n",
              "      <th>inconclusive</th>\n",
              "      <th>vader_neg</th>\n",
              "      <th>vader_neu</th>\n",
              "      <th>vader_pos</th>\n",
              "      <th>domain</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bucket</th>\n",
              "      <th>subdomain</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"4\" valign=\"top\">Everyday Morality</th>\n",
              "      <th>AmItheAsshole</th>\n",
              "      <td>1011</td>\n",
              "      <td>1011</td>\n",
              "      <td>1011</td>\n",
              "      <td>1011</td>\n",
              "      <td>1011</td>\n",
              "      <td>1011</td>\n",
              "      <td>1011</td>\n",
              "      <td>1011</td>\n",
              "      <td>1011</td>\n",
              "      <td>1011</td>\n",
              "      <td>...</td>\n",
              "      <td>1011</td>\n",
              "      <td>1011</td>\n",
              "      <td>1011</td>\n",
              "      <td>1011</td>\n",
              "      <td>1011</td>\n",
              "      <td>1011</td>\n",
              "      <td>1011</td>\n",
              "      <td>1011</td>\n",
              "      <td>1011</td>\n",
              "      <td>1011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>confession</th>\n",
              "      <td>1006</td>\n",
              "      <td>1006</td>\n",
              "      <td>1006</td>\n",
              "      <td>1006</td>\n",
              "      <td>1006</td>\n",
              "      <td>1006</td>\n",
              "      <td>1006</td>\n",
              "      <td>1006</td>\n",
              "      <td>1006</td>\n",
              "      <td>1006</td>\n",
              "      <td>...</td>\n",
              "      <td>1006</td>\n",
              "      <td>1006</td>\n",
              "      <td>1006</td>\n",
              "      <td>1006</td>\n",
              "      <td>1006</td>\n",
              "      <td>1006</td>\n",
              "      <td>1006</td>\n",
              "      <td>1006</td>\n",
              "      <td>1006</td>\n",
              "      <td>1006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>nostalgia</th>\n",
              "      <td>1206</td>\n",
              "      <td>1206</td>\n",
              "      <td>1206</td>\n",
              "      <td>1206</td>\n",
              "      <td>1206</td>\n",
              "      <td>1206</td>\n",
              "      <td>1206</td>\n",
              "      <td>1206</td>\n",
              "      <td>1206</td>\n",
              "      <td>1206</td>\n",
              "      <td>...</td>\n",
              "      <td>1206</td>\n",
              "      <td>1206</td>\n",
              "      <td>1206</td>\n",
              "      <td>1206</td>\n",
              "      <td>1206</td>\n",
              "      <td>1206</td>\n",
              "      <td>1206</td>\n",
              "      <td>1206</td>\n",
              "      <td>1206</td>\n",
              "      <td>1206</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>relationship_advice</th>\n",
              "      <td>1043</td>\n",
              "      <td>1043</td>\n",
              "      <td>1043</td>\n",
              "      <td>1043</td>\n",
              "      <td>1043</td>\n",
              "      <td>1043</td>\n",
              "      <td>1043</td>\n",
              "      <td>1043</td>\n",
              "      <td>1043</td>\n",
              "      <td>1043</td>\n",
              "      <td>...</td>\n",
              "      <td>1043</td>\n",
              "      <td>1043</td>\n",
              "      <td>1043</td>\n",
              "      <td>1043</td>\n",
              "      <td>1043</td>\n",
              "      <td>1043</td>\n",
              "      <td>1043</td>\n",
              "      <td>1043</td>\n",
              "      <td>1043</td>\n",
              "      <td>1043</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"5\" valign=\"top\">French politics</th>\n",
              "      <th>Conservative</th>\n",
              "      <td>103</td>\n",
              "      <td>103</td>\n",
              "      <td>103</td>\n",
              "      <td>103</td>\n",
              "      <td>103</td>\n",
              "      <td>103</td>\n",
              "      <td>103</td>\n",
              "      <td>103</td>\n",
              "      <td>103</td>\n",
              "      <td>103</td>\n",
              "      <td>...</td>\n",
              "      <td>103</td>\n",
              "      <td>103</td>\n",
              "      <td>103</td>\n",
              "      <td>103</td>\n",
              "      <td>103</td>\n",
              "      <td>103</td>\n",
              "      <td>103</td>\n",
              "      <td>103</td>\n",
              "      <td>103</td>\n",
              "      <td>103</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>europe</th>\n",
              "      <td>2050</td>\n",
              "      <td>2050</td>\n",
              "      <td>2050</td>\n",
              "      <td>2050</td>\n",
              "      <td>2050</td>\n",
              "      <td>2050</td>\n",
              "      <td>2050</td>\n",
              "      <td>2050</td>\n",
              "      <td>2050</td>\n",
              "      <td>2050</td>\n",
              "      <td>...</td>\n",
              "      <td>2050</td>\n",
              "      <td>2050</td>\n",
              "      <td>2050</td>\n",
              "      <td>2050</td>\n",
              "      <td>2050</td>\n",
              "      <td>2050</td>\n",
              "      <td>2050</td>\n",
              "      <td>2050</td>\n",
              "      <td>2050</td>\n",
              "      <td>2050</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>geopolitics</th>\n",
              "      <td>99</td>\n",
              "      <td>99</td>\n",
              "      <td>99</td>\n",
              "      <td>99</td>\n",
              "      <td>99</td>\n",
              "      <td>99</td>\n",
              "      <td>99</td>\n",
              "      <td>99</td>\n",
              "      <td>99</td>\n",
              "      <td>99</td>\n",
              "      <td>...</td>\n",
              "      <td>99</td>\n",
              "      <td>99</td>\n",
              "      <td>99</td>\n",
              "      <td>99</td>\n",
              "      <td>99</td>\n",
              "      <td>99</td>\n",
              "      <td>99</td>\n",
              "      <td>99</td>\n",
              "      <td>99</td>\n",
              "      <td>99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>neoliberal</th>\n",
              "      <td>1346</td>\n",
              "      <td>1346</td>\n",
              "      <td>1346</td>\n",
              "      <td>1346</td>\n",
              "      <td>1346</td>\n",
              "      <td>1346</td>\n",
              "      <td>1346</td>\n",
              "      <td>1346</td>\n",
              "      <td>1346</td>\n",
              "      <td>1346</td>\n",
              "      <td>...</td>\n",
              "      <td>1346</td>\n",
              "      <td>1346</td>\n",
              "      <td>1346</td>\n",
              "      <td>1346</td>\n",
              "      <td>1346</td>\n",
              "      <td>1346</td>\n",
              "      <td>1346</td>\n",
              "      <td>1346</td>\n",
              "      <td>1346</td>\n",
              "      <td>1346</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>worldnews</th>\n",
              "      <td>1960</td>\n",
              "      <td>1960</td>\n",
              "      <td>1960</td>\n",
              "      <td>1960</td>\n",
              "      <td>1960</td>\n",
              "      <td>1960</td>\n",
              "      <td>1960</td>\n",
              "      <td>1960</td>\n",
              "      <td>1960</td>\n",
              "      <td>1960</td>\n",
              "      <td>...</td>\n",
              "      <td>1960</td>\n",
              "      <td>1960</td>\n",
              "      <td>1960</td>\n",
              "      <td>1960</td>\n",
              "      <td>1960</td>\n",
              "      <td>1960</td>\n",
              "      <td>1960</td>\n",
              "      <td>1960</td>\n",
              "      <td>1960</td>\n",
              "      <td>1960</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"3\" valign=\"top\">US Politics</th>\n",
              "      <th>Conservative</th>\n",
              "      <td>1379</td>\n",
              "      <td>1379</td>\n",
              "      <td>1379</td>\n",
              "      <td>1379</td>\n",
              "      <td>1379</td>\n",
              "      <td>1379</td>\n",
              "      <td>1379</td>\n",
              "      <td>1379</td>\n",
              "      <td>1379</td>\n",
              "      <td>1379</td>\n",
              "      <td>...</td>\n",
              "      <td>1379</td>\n",
              "      <td>1379</td>\n",
              "      <td>1379</td>\n",
              "      <td>1379</td>\n",
              "      <td>1379</td>\n",
              "      <td>1379</td>\n",
              "      <td>1379</td>\n",
              "      <td>1379</td>\n",
              "      <td>1379</td>\n",
              "      <td>1379</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>antiwork</th>\n",
              "      <td>1424</td>\n",
              "      <td>1424</td>\n",
              "      <td>1424</td>\n",
              "      <td>1424</td>\n",
              "      <td>1424</td>\n",
              "      <td>1424</td>\n",
              "      <td>1424</td>\n",
              "      <td>1424</td>\n",
              "      <td>1424</td>\n",
              "      <td>1424</td>\n",
              "      <td>...</td>\n",
              "      <td>1424</td>\n",
              "      <td>1424</td>\n",
              "      <td>1424</td>\n",
              "      <td>1424</td>\n",
              "      <td>1424</td>\n",
              "      <td>1424</td>\n",
              "      <td>1424</td>\n",
              "      <td>1424</td>\n",
              "      <td>1424</td>\n",
              "      <td>1424</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>politics</th>\n",
              "      <td>1368</td>\n",
              "      <td>1368</td>\n",
              "      <td>1368</td>\n",
              "      <td>1368</td>\n",
              "      <td>1368</td>\n",
              "      <td>1368</td>\n",
              "      <td>1368</td>\n",
              "      <td>1368</td>\n",
              "      <td>1368</td>\n",
              "      <td>1368</td>\n",
              "      <td>...</td>\n",
              "      <td>1368</td>\n",
              "      <td>1368</td>\n",
              "      <td>1368</td>\n",
              "      <td>1368</td>\n",
              "      <td>1368</td>\n",
              "      <td>1368</td>\n",
              "      <td>1368</td>\n",
              "      <td>1368</td>\n",
              "      <td>1368</td>\n",
              "      <td>1368</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>12 rows \u00d7 23 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       text  cleaned_text  annotation  \\\n",
              "bucket            subdomain                                             \n",
              "Everyday Morality AmItheAsshole        1011          1011        1011   \n",
              "                  confession           1006          1006        1006   \n",
              "                  nostalgia            1206          1206        1206   \n",
              "                  relationship_advice  1043          1043        1043   \n",
              "French politics   Conservative          103           103         103   \n",
              "                  europe               2050          2050        2050   \n",
              "                  geopolitics            99            99          99   \n",
              "                  neoliberal           1346          1346        1346   \n",
              "                  worldnews            1960          1960        1960   \n",
              "US Politics       Conservative         1379          1379        1379   \n",
              "                  antiwork             1424          1424        1424   \n",
              "                  politics             1368          1368        1368   \n",
              "\n",
              "                                       final_annotation  care  fairness  \\\n",
              "bucket            subdomain                                               \n",
              "Everyday Morality AmItheAsshole                    1011  1011      1011   \n",
              "                  confession                       1006  1006      1006   \n",
              "                  nostalgia                        1206  1206      1206   \n",
              "                  relationship_advice              1043  1043      1043   \n",
              "French politics   Conservative                      103   103       103   \n",
              "                  europe                           2050  2050      2050   \n",
              "                  geopolitics                        99    99        99   \n",
              "                  neoliberal                       1346  1346      1346   \n",
              "                  worldnews                        1960  1960      1960   \n",
              "US Politics       Conservative                     1379  1379      1379   \n",
              "                  antiwork                         1424  1424      1424   \n",
              "                  politics                         1368  1368      1368   \n",
              "\n",
              "                                       loyalty  authority  purity  harm  ...  \\\n",
              "bucket            subdomain                                              ...   \n",
              "Everyday Morality AmItheAsshole           1011       1011    1011  1011  ...   \n",
              "                  confession              1006       1006    1006  1006  ...   \n",
              "                  nostalgia               1206       1206    1206  1206  ...   \n",
              "                  relationship_advice     1043       1043    1043  1043  ...   \n",
              "French politics   Conservative             103        103     103   103  ...   \n",
              "                  europe                  2050       2050    2050  2050  ...   \n",
              "                  geopolitics               99         99      99    99  ...   \n",
              "                  neoliberal              1346       1346    1346  1346  ...   \n",
              "                  worldnews               1960       1960    1960  1960  ...   \n",
              "US Politics       Conservative            1379       1379    1379  1379  ...   \n",
              "                  antiwork                1424       1424    1424  1424  ...   \n",
              "                  politics                1368       1368    1368  1368  ...   \n",
              "\n",
              "                                       degradation  equality  proportionality  \\\n",
              "bucket            subdomain                                                     \n",
              "Everyday Morality AmItheAsshole               1011      1011             1011   \n",
              "                  confession                  1006      1006             1006   \n",
              "                  nostalgia                   1206      1206             1206   \n",
              "                  relationship_advice         1043      1043             1043   \n",
              "French politics   Conservative                 103       103              103   \n",
              "                  europe                      2050      2050             2050   \n",
              "                  geopolitics                   99        99               99   \n",
              "                  neoliberal                  1346      1346             1346   \n",
              "                  worldnews                   1960      1960             1960   \n",
              "US Politics       Conservative                1379      1379             1379   \n",
              "                  antiwork                    1424      1424             1424   \n",
              "                  politics                    1368      1368             1368   \n",
              "\n",
              "                                       thin morality  non-moral  inconclusive  \\\n",
              "bucket            subdomain                                                     \n",
              "Everyday Morality AmItheAsshole                 1011       1011          1011   \n",
              "                  confession                    1006       1006          1006   \n",
              "                  nostalgia                     1206       1206          1206   \n",
              "                  relationship_advice           1043       1043          1043   \n",
              "French politics   Conservative                   103        103           103   \n",
              "                  europe                        2050       2050          2050   \n",
              "                  geopolitics                     99         99            99   \n",
              "                  neoliberal                    1346       1346          1346   \n",
              "                  worldnews                     1960       1960          1960   \n",
              "US Politics       Conservative                  1379       1379          1379   \n",
              "                  antiwork                      1424       1424          1424   \n",
              "                  politics                      1368       1368          1368   \n",
              "\n",
              "                                       vader_neg  vader_neu  vader_pos  domain  \n",
              "bucket            subdomain                                                     \n",
              "Everyday Morality AmItheAsshole             1011       1011       1011    1011  \n",
              "                  confession                1006       1006       1006    1006  \n",
              "                  nostalgia                 1206       1206       1206    1206  \n",
              "                  relationship_advice       1043       1043       1043    1043  \n",
              "French politics   Conservative               103        103        103     103  \n",
              "                  europe                    2050       2050       2050    2050  \n",
              "                  geopolitics                 99         99         99      99  \n",
              "                  neoliberal                1346       1346       1346    1346  \n",
              "                  worldnews                 1960       1960       1960    1960  \n",
              "US Politics       Conservative              1379       1379       1379    1379  \n",
              "                  antiwork                  1424       1424       1424    1424  \n",
              "                  politics                  1368       1368       1368    1368  \n",
              "\n",
              "[12 rows x 23 columns]"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mfrc_df.groupby(['bucket','subdomain']).count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "YrMXxC5RrCmX"
      },
      "outputs": [],
      "source": [
        "mfrc_df['non-moral'] = mfrc_df['final_annotation'].apply(lambda x: 1 if x == 'Non-Moral' else 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nliGHfcIrCmX",
        "outputId": "ee55ada7-c552-4151-baa5-56942b58a4be"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(13995, 25)"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mfrc_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BVTQWpwErCmX",
        "outputId": "ad2d635b-283e-440b-e157-1924c914da6c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "care             737\n",
              "harm            1014\n",
              "fairness         623\n",
              "cheating         841\n",
              "loyalty          241\n",
              "betrayal         188\n",
              "authority        330\n",
              "subversion       357\n",
              "purity           100\n",
              "degradation      187\n",
              "domain         13995\n",
              "non-moral       9843\n",
              "dtype: int64"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "category_counts = mfrc_df[['care','harm', 'fairness', 'cheating', 'loyalty', \n",
        "       'betrayal', 'authority','subversion', 'purity', 'degradation', 'domain', 'non-moral']].sum()\n",
        "category_counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>cleaned_text</th>\n",
              "      <th>subdomain</th>\n",
              "      <th>bucket</th>\n",
              "      <th>annotation</th>\n",
              "      <th>final_annotation</th>\n",
              "      <th>care</th>\n",
              "      <th>harm</th>\n",
              "      <th>fairness</th>\n",
              "      <th>cheating</th>\n",
              "      <th>...</th>\n",
              "      <th>degradation</th>\n",
              "      <th>equality</th>\n",
              "      <th>proportionality</th>\n",
              "      <th>thin morality</th>\n",
              "      <th>non-moral</th>\n",
              "      <th>inconclusive</th>\n",
              "      <th>vader_neg</th>\n",
              "      <th>vader_neu</th>\n",
              "      <th>vader_pos</th>\n",
              "      <th>domain</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/r/france is pretty lively, with it's own ling...</td>\n",
              "      <td>/r/france is pretty lively, with it's own ling...</td>\n",
              "      <td>europe</td>\n",
              "      <td>French politics</td>\n",
              "      <td>{'annotator03': {'annotation': 'Non-Moral', 'c...</td>\n",
              "      <td>Non-Moral</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.142</td>\n",
              "      <td>0.679</td>\n",
              "      <td>0.180</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>it really is a very unusual situation isn't it...</td>\n",
              "      <td>it really is a very unusual situation isn't it...</td>\n",
              "      <td>europe</td>\n",
              "      <td>French politics</td>\n",
              "      <td>{'annotator03': {'annotation': 'Non-Moral', 'c...</td>\n",
              "      <td>Non-Moral</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.118</td>\n",
              "      <td>0.772</td>\n",
              "      <td>0.110</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Macrons face just screams\\n\"I do not know her,...</td>\n",
              "      <td>Macrons face just screams \"I do not know her, ...</td>\n",
              "      <td>europe</td>\n",
              "      <td>French politics</td>\n",
              "      <td>{'annotator03': {'annotation': 'Non-Moral', 'c...</td>\n",
              "      <td>Non-Moral</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.135</td>\n",
              "      <td>0.865</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Clinton lead polls by 4%, well within a reason...</td>\n",
              "      <td>Clinton lead polls by 4%, well within a reason...</td>\n",
              "      <td>worldnews</td>\n",
              "      <td>French politics</td>\n",
              "      <td>{'annotator03': {'annotation': 'Non-Moral', 'c...</td>\n",
              "      <td>Non-Moral</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.094</td>\n",
              "      <td>0.833</td>\n",
              "      <td>0.073</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Hey, fuck you. Us leftists will never support ...</td>\n",
              "      <td>Hey, fuck you. Us leftists will never support ...</td>\n",
              "      <td>worldnews</td>\n",
              "      <td>French politics</td>\n",
              "      <td>{'annotator03': {'annotation': 'Loyalty,Equali...</td>\n",
              "      <td>Equality</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.391</td>\n",
              "      <td>0.609</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17734</th>\n",
              "      <td>\u201cI don\u2019t want words, I want action!\u201d   \\n\\nCoo...</td>\n",
              "      <td>I don t want words, I want action! Cool, elect...</td>\n",
              "      <td>politics</td>\n",
              "      <td>US Politics</td>\n",
              "      <td>{'annotator01': {'annotation': 'Authority', 'c...</td>\n",
              "      <td>Non-Moral</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.089</td>\n",
              "      <td>0.605</td>\n",
              "      <td>0.306</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17735</th>\n",
              "      <td>Music, history, nature channels have all turne...</td>\n",
              "      <td>Music, history, nature channels have all turne...</td>\n",
              "      <td>Conservative</td>\n",
              "      <td>US Politics</td>\n",
              "      <td>{'annotator01': {'annotation': 'Non-Moral', 'c...</td>\n",
              "      <td>Non-Moral</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.921</td>\n",
              "      <td>0.079</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17737</th>\n",
              "      <td>Not being discriminated against\\n\\n\\nBeing pro...</td>\n",
              "      <td>Not being discriminated against Being protecte...</td>\n",
              "      <td>Conservative</td>\n",
              "      <td>US Politics</td>\n",
              "      <td>{'annotator01': {'annotation': 'Equality', 'co...</td>\n",
              "      <td>Equality</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.134</td>\n",
              "      <td>0.738</td>\n",
              "      <td>0.128</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17738</th>\n",
              "      <td>*Jaime [Lannister] reached for the flagon to r...</td>\n",
              "      <td>*Jaime [Lannister] reached for the flagon to r...</td>\n",
              "      <td>politics</td>\n",
              "      <td>US Politics</td>\n",
              "      <td>{'annotator01': {'annotation': 'Authority', 'c...</td>\n",
              "      <td>Authority</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.098</td>\n",
              "      <td>0.767</td>\n",
              "      <td>0.135</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17739</th>\n",
              "      <td>I don't think you understand how much American...</td>\n",
              "      <td>I don't think you understand how much American...</td>\n",
              "      <td>Conservative</td>\n",
              "      <td>US Politics</td>\n",
              "      <td>{'annotator01': {'annotation': 'Non-Moral', 'c...</td>\n",
              "      <td>Non-Moral</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.962</td>\n",
              "      <td>0.038</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>13995 rows \u00d7 25 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    text  \\\n",
              "1      /r/france is pretty lively, with it's own ling...   \n",
              "3      it really is a very unusual situation isn't it...   \n",
              "5      Macrons face just screams\\n\"I do not know her,...   \n",
              "6      Clinton lead polls by 4%, well within a reason...   \n",
              "7      Hey, fuck you. Us leftists will never support ...   \n",
              "...                                                  ...   \n",
              "17734  \u201cI don\u2019t want words, I want action!\u201d   \\n\\nCoo...   \n",
              "17735  Music, history, nature channels have all turne...   \n",
              "17737  Not being discriminated against\\n\\n\\nBeing pro...   \n",
              "17738  *Jaime [Lannister] reached for the flagon to r...   \n",
              "17739  I don't think you understand how much American...   \n",
              "\n",
              "                                            cleaned_text     subdomain  \\\n",
              "1      /r/france is pretty lively, with it's own ling...        europe   \n",
              "3      it really is a very unusual situation isn't it...        europe   \n",
              "5      Macrons face just screams \"I do not know her, ...        europe   \n",
              "6      Clinton lead polls by 4%, well within a reason...     worldnews   \n",
              "7      Hey, fuck you. Us leftists will never support ...     worldnews   \n",
              "...                                                  ...           ...   \n",
              "17734  I don t want words, I want action! Cool, elect...      politics   \n",
              "17735  Music, history, nature channels have all turne...  Conservative   \n",
              "17737  Not being discriminated against Being protecte...  Conservative   \n",
              "17738  *Jaime [Lannister] reached for the flagon to r...      politics   \n",
              "17739  I don't think you understand how much American...  Conservative   \n",
              "\n",
              "                bucket                                         annotation  \\\n",
              "1      French politics  {'annotator03': {'annotation': 'Non-Moral', 'c...   \n",
              "3      French politics  {'annotator03': {'annotation': 'Non-Moral', 'c...   \n",
              "5      French politics  {'annotator03': {'annotation': 'Non-Moral', 'c...   \n",
              "6      French politics  {'annotator03': {'annotation': 'Non-Moral', 'c...   \n",
              "7      French politics  {'annotator03': {'annotation': 'Loyalty,Equali...   \n",
              "...                ...                                                ...   \n",
              "17734      US Politics  {'annotator01': {'annotation': 'Authority', 'c...   \n",
              "17735      US Politics  {'annotator01': {'annotation': 'Non-Moral', 'c...   \n",
              "17737      US Politics  {'annotator01': {'annotation': 'Equality', 'co...   \n",
              "17738      US Politics  {'annotator01': {'annotation': 'Authority', 'c...   \n",
              "17739      US Politics  {'annotator01': {'annotation': 'Non-Moral', 'c...   \n",
              "\n",
              "      final_annotation  care  harm  fairness  cheating  ...  degradation  \\\n",
              "1            Non-Moral     0     0         0         0  ...            0   \n",
              "3            Non-Moral     0     0         0         0  ...            0   \n",
              "5            Non-Moral     0     0         0         0  ...            0   \n",
              "6            Non-Moral     0     0         0         0  ...            0   \n",
              "7             Equality     0     0         0         1  ...            0   \n",
              "...                ...   ...   ...       ...       ...  ...          ...   \n",
              "17734        Non-Moral     0     0         0         0  ...            0   \n",
              "17735        Non-Moral     0     0         0         0  ...            0   \n",
              "17737         Equality     0     0         0         1  ...            0   \n",
              "17738        Authority     0     0         0         0  ...            0   \n",
              "17739        Non-Moral     0     0         0         0  ...            0   \n",
              "\n",
              "       equality  proportionality  thin morality  non-moral  inconclusive  \\\n",
              "1             0                0              0          1             0   \n",
              "3             0                0              0          1             0   \n",
              "5             0                0              0          1             0   \n",
              "6             0                0              0          1             0   \n",
              "7             1                0              0          0             0   \n",
              "...         ...              ...            ...        ...           ...   \n",
              "17734         0                0              0          1             0   \n",
              "17735         0                0              0          1             0   \n",
              "17737         1                0              0          0             0   \n",
              "17738         0                0              0          0             0   \n",
              "17739         0                0              0          1             0   \n",
              "\n",
              "       vader_neg  vader_neu  vader_pos  domain  \n",
              "1          0.142      0.679      0.180       1  \n",
              "3          0.118      0.772      0.110       1  \n",
              "5          0.135      0.865      0.000       1  \n",
              "6          0.094      0.833      0.073       1  \n",
              "7          0.391      0.609      0.000       1  \n",
              "...          ...        ...        ...     ...  \n",
              "17734      0.089      0.605      0.306       1  \n",
              "17735      0.000      0.921      0.079       1  \n",
              "17737      0.134      0.738      0.128       1  \n",
              "17738      0.098      0.767      0.135       1  \n",
              "17739      0.000      0.962      0.038       1  \n",
              "\n",
              "[13995 rows x 25 columns]"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mfrc_df[['text', 'cleaned_text', 'subdomain', 'bucket', 'annotation',\n",
        "       'final_annotation', 'care','harm', 'fairness','cheating', 'loyalty', 'betrayal', \n",
        "       'authority', 'subversion', 'purity', 'degradation',\n",
        "       'equality', 'proportionality', 'thin morality', 'non-moral',\n",
        "       'inconclusive', 'vader_neg', 'vader_neu', 'vader_pos', 'domain']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3blEZtyLya1"
      },
      "source": [
        "####\u00a0Facebook:\n",
        "- For the facebook data, please contact the authors of this paper: https://dl.acm.org/doi/10.1145/3543507.3583865\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "sTTpODnuLya1"
      },
      "outputs": [],
      "source": [
        "mffp_df = pd.read_csv('path/to/downloaded/FbVaccinationPosts/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "86uUYdR0Lya1"
      },
      "outputs": [],
      "source": [
        "mffp_df['domain'] = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 533
        },
        "id": "aDQ78BbfLya2",
        "outputId": "a4474cae-d5b8-4cb5-e12a-04029d71270f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>cleaned_text</th>\n",
              "      <th>comment_id</th>\n",
              "      <th>page_id</th>\n",
              "      <th>page</th>\n",
              "      <th>class</th>\n",
              "      <th>care</th>\n",
              "      <th>harm</th>\n",
              "      <th>fairness</th>\n",
              "      <th>cheating</th>\n",
              "      <th>...</th>\n",
              "      <th>betrayal</th>\n",
              "      <th>authority</th>\n",
              "      <th>subversion</th>\n",
              "      <th>purity</th>\n",
              "      <th>degradation</th>\n",
              "      <th>liberty</th>\n",
              "      <th>oppression</th>\n",
              "      <th>non-moral</th>\n",
              "      <th>subdomain</th>\n",
              "      <th>domain</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I just contacted my rep. Julia Brown and reque...</td>\n",
              "      <td>I just contacted my rep. Julia Brown and reque...</td>\n",
              "      <td>1525407617778182_1525810737737870</td>\n",
              "      <td>1374879262831019</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>vaccination</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The thing is, myself, and many other people ar...</td>\n",
              "      <td>The thing is, myself, and many other people ar...</td>\n",
              "      <td>2563364117066915_2563717157031611</td>\n",
              "      <td>414643305272351</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>vaccination</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Soooooo....how do they explain all the dead ki...</td>\n",
              "      <td>Soooooo....how do they explain all the dead ki...</td>\n",
              "      <td>2563364117066915_2563383687064958</td>\n",
              "      <td>414643305272351</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>vaccination</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Well writer, I\u2019m going to use a bit of your so...</td>\n",
              "      <td>Well writer, I m going to use a bit of your so...</td>\n",
              "      <td>2563364117066915_2563432760393384</td>\n",
              "      <td>414643305272351</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>vaccination</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Well imo, F***k the AVN! I am proud to say my ...</td>\n",
              "      <td>Well imo, F***k the AVN! I am proud to say my ...</td>\n",
              "      <td>10152270557898588_31662936</td>\n",
              "      <td>143367983587</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>vaccination</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows \u00d7 21 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  \\\n",
              "0  I just contacted my rep. Julia Brown and reque...   \n",
              "1  The thing is, myself, and many other people ar...   \n",
              "2  Soooooo....how do they explain all the dead ki...   \n",
              "3  Well writer, I\u2019m going to use a bit of your so...   \n",
              "4  Well imo, F***k the AVN! I am proud to say my ...   \n",
              "\n",
              "                                        cleaned_text  \\\n",
              "0  I just contacted my rep. Julia Brown and reque...   \n",
              "1  The thing is, myself, and many other people ar...   \n",
              "2  Soooooo....how do they explain all the dead ki...   \n",
              "3  Well writer, I m going to use a bit of your so...   \n",
              "4  Well imo, F***k the AVN! I am proud to say my ...   \n",
              "\n",
              "                          comment_id           page_id  page  class  care  \\\n",
              "0  1525407617778182_1525810737737870  1374879262831019     1      0   0.0   \n",
              "1  2563364117066915_2563717157031611   414643305272351     1      1   1.0   \n",
              "2  2563364117066915_2563383687064958   414643305272351     1      1   0.0   \n",
              "3  2563364117066915_2563432760393384   414643305272351     1      1   0.0   \n",
              "4         10152270557898588_31662936      143367983587     1      1   0.0   \n",
              "\n",
              "   harm  fairness  cheating  ...  betrayal  authority  subversion  purity  \\\n",
              "0   0.0       1.0       0.0  ...       0.0        0.0         0.0     0.0   \n",
              "1   0.0       0.0       0.0  ...       1.0        0.0         0.0     0.0   \n",
              "2   0.0       0.0       0.0  ...       0.0        0.0         0.0     0.0   \n",
              "3   0.0       1.0       0.0  ...       0.0        0.0         0.0     0.0   \n",
              "4   0.0       0.0       0.0  ...       0.0        0.0         0.0     0.0   \n",
              "\n",
              "   degradation  liberty  oppression  non-moral    subdomain domain  \n",
              "0          0.0      0.0         0.0          0  vaccination      2  \n",
              "1          0.0      0.0         0.0          0  vaccination      2  \n",
              "2          0.0      0.0         0.0          1  vaccination      2  \n",
              "3          0.0      0.0         0.0          0  vaccination      2  \n",
              "4          0.0      0.0         0.0          1  vaccination      2  \n",
              "\n",
              "[5 rows x 21 columns]"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mffp_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BYrjtBtCrCma",
        "outputId": "33df6fe6-2e62-4926-dea1-710f9d79012a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "care            357.0\n",
              "harm            132.0\n",
              "fairness        174.0\n",
              "cheating        123.0\n",
              "loyalty          40.0\n",
              "betrayal         38.0\n",
              "authority       110.0\n",
              "subversion      204.0\n",
              "purity           80.0\n",
              "degradation     112.0\n",
              "domain         3020.0\n",
              "non-moral       248.0\n",
              "dtype: float64"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "category_counts = mffp_df[['care','harm', 'fairness', 'cheating', 'loyalty', \n",
        "       'betrayal', 'authority','subversion', 'purity', 'degradation', 'domain', 'non-moral']].sum()\n",
        "category_counts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HTrfmIBPLya2"
      },
      "source": [
        "#### Concatenate the datasets together based on 10 Moral Values: Care/Harm, Fairness/Cheating, Loyalty/Betrayal Authority/Subversion and Purity/Degradation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "R7X8j9Ceie-6"
      },
      "outputs": [],
      "source": [
        "mft_columns = ['care', 'harm', 'fairness', 'cheating', 'loyalty', 'betrayal',\n",
        "       'authority', 'subversion', 'purity', 'degradation']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "zhhuUr7pijpH"
      },
      "outputs": [],
      "source": [
        "cat_columns = [\"cleaned_text\"]+mft_columns+[\"subdomain\", \"domain\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "3mtdt1bxLya2"
      },
      "outputs": [],
      "source": [
        "df = pd.concat([mftc_df[cat_columns], mfrc_df[cat_columns], mffp_df[cat_columns]], axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "vK6zeYdSLya2"
      },
      "outputs": [],
      "source": [
        "df = df.dropna(subset = ['cleaned_text'])\n",
        "df = df.drop_duplicates(subset = ['cleaned_text'])\n",
        "df = df[~(df[['care', 'fairness', 'loyalty', 'authority', 'purity', \"harm\", \"subversion\", \"degradation\", \"cheating\", \"betrayal\"]] == 2).any(axis=1)]\n",
        "df.reset_index(drop = True, inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "-PgDd0yzLya2",
        "outputId": "bd570ec4-d580-4ed5-ed56-baca3d98fe84"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cleaned_text</th>\n",
              "      <th>care</th>\n",
              "      <th>harm</th>\n",
              "      <th>fairness</th>\n",
              "      <th>cheating</th>\n",
              "      <th>loyalty</th>\n",
              "      <th>betrayal</th>\n",
              "      <th>authority</th>\n",
              "      <th>subversion</th>\n",
              "      <th>purity</th>\n",
              "      <th>degradation</th>\n",
              "      <th>subdomain</th>\n",
              "      <th>domain</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The courage to be impatient with evil and pati...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>BLM</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>but OMFG already. enraged_face Protect and ser...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>BLM</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>stop shaving, it's your manly dignity</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>BLM</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ARABS MORTAL HATRED AND ENSLAVEMENT OF THE BLA...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>BLM</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@user: is my hero! @user True patriot</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>BLM</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34296</th>\n",
              "      <td>Sadly most Canadians wont ever research vaccin...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>vaccination</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34297</th>\n",
              "      <td>Stop poisoning the children</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>vaccination</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34298</th>\n",
              "      <td>Was pregnant and ended up with the flu back in...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>vaccination</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34299</th>\n",
              "      <td>My mother developed shingles last year and she...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>vaccination</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34300</th>\n",
              "      <td>Don't trust your county health departments. Th...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>vaccination</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>34301 rows \u00d7 13 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            cleaned_text  care  harm  \\\n",
              "0      The courage to be impatient with evil and pati...   0.0   0.0   \n",
              "1      but OMFG already. enraged_face Protect and ser...   0.0   1.0   \n",
              "2                  stop shaving, it's your manly dignity   0.0   0.0   \n",
              "3      ARABS MORTAL HATRED AND ENSLAVEMENT OF THE BLA...   0.0   1.0   \n",
              "4                  @user: is my hero! @user True patriot   0.0   0.0   \n",
              "...                                                  ...   ...   ...   \n",
              "34296  Sadly most Canadians wont ever research vaccin...   1.0   0.0   \n",
              "34297                        Stop poisoning the children   1.0   0.0   \n",
              "34298  Was pregnant and ended up with the flu back in...   1.0   0.0   \n",
              "34299  My mother developed shingles last year and she...   1.0   0.0   \n",
              "34300  Don't trust your county health departments. Th...   0.0   0.0   \n",
              "\n",
              "       fairness  cheating  loyalty  betrayal  authority  subversion  purity  \\\n",
              "0           1.0       0.0      0.0       0.0        0.0         0.0     0.0   \n",
              "1           0.0       0.0      0.0       0.0        0.0         0.0     0.0   \n",
              "2           0.0       0.0      0.0       0.0        0.0         0.0     0.0   \n",
              "3           0.0       0.0      0.0       0.0        0.0         0.0     0.0   \n",
              "4           0.0       0.0      0.0       0.0        0.0         0.0     0.0   \n",
              "...         ...       ...      ...       ...        ...         ...     ...   \n",
              "34296       0.0       0.0      0.0       0.0        0.0         0.0     0.0   \n",
              "34297       0.0       0.0      0.0       0.0        0.0         0.0     1.0   \n",
              "34298       0.0       0.0      0.0       0.0        0.0         0.0     0.0   \n",
              "34299       0.0       0.0      0.0       0.0        0.0         0.0     0.0   \n",
              "34300       0.0       0.0      0.0       1.0        0.0         1.0     0.0   \n",
              "\n",
              "       degradation    subdomain  domain  \n",
              "0              0.0          BLM       0  \n",
              "1              0.0          BLM       0  \n",
              "2              0.0          BLM       0  \n",
              "3              0.0          BLM       0  \n",
              "4              0.0          BLM       0  \n",
              "...            ...          ...     ...  \n",
              "34296          0.0  vaccination       2  \n",
              "34297          0.0  vaccination       2  \n",
              "34298          0.0  vaccination       2  \n",
              "34299          0.0  vaccination       2  \n",
              "34300          0.0  vaccination       2  \n",
              "\n",
              "[34301 rows x 13 columns]"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Al6pwrwKrCmd",
        "outputId": "9b75c7d4-a014-46be-f836-4873c1d8e2b1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(34301, 13)"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "subdomain\n",
              "Elections              3912\n",
              "BLM                    3383\n",
              "Baltimore              3345\n",
              "Sandy                  3102\n",
              "Davidson               2716\n",
              "ALM                    2340\n",
              "europe                 2050\n",
              "worldnews              1960\n",
              "vaccination            1509\n",
              "Conservative           1482\n",
              "antiwork               1424\n",
              "politics               1368\n",
              "neoliberal             1345\n",
              "nostalgia              1206\n",
              "relationship_advice    1043\n",
              "AmItheAsshole          1011\n",
              "confession             1006\n",
              "geopolitics              99\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.subdomain.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "care           2752.0\n",
              "harm           3173.0\n",
              "fairness       2369.0\n",
              "cheating       3001.0\n",
              "loyalty        1308.0\n",
              "betrayal       1564.0\n",
              "authority      1264.0\n",
              "subversion     1126.0\n",
              "purity          715.0\n",
              "degradation    1045.0\n",
              "dtype: float64"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df[['care', 'harm', 'fairness', 'cheating', 'loyalty',\n",
        "       'betrayal', 'authority', 'subversion', 'purity', 'degradation']].sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Neutral (Non-Moral) text:  17948\n"
          ]
        }
      ],
      "source": [
        "neutral_text = df[(df['care']==0) & (df['harm']==0) \n",
        "   & (df['fairness']==0) & (df['cheating']==0) \n",
        "   & (df['loyalty']==0)  & (df['betrayal']==0)\n",
        "   & (df['authority']==0)& (df['subversion']==0)  \n",
        "   & (df['purity']==0) & (df['degradation']==0)]\n",
        "\n",
        "print(\"Neutral (Non-Moral) text: \", len(neutral_text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.5232500510189207"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(neutral_text)/len(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxIe_CxgLya3"
      },
      "source": [
        "#### Suffle the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "kRTaXazSLya3"
      },
      "outputs": [],
      "source": [
        "df = df.sample(frac=1).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qy_UEUL8Lya3",
        "outputId": "77e1de6c-b242-499e-b992-e6d73155410f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(34301, 13)"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l0fgjPMuLya-",
        "outputId": "1b936dce-078c-4472-8751-a88eb3170f65"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "cleaned_text    0\n",
              "care            0\n",
              "harm            0\n",
              "fairness        0\n",
              "cheating        0\n",
              "loyalty         0\n",
              "betrayal        0\n",
              "authority       0\n",
              "subversion      0\n",
              "purity          0\n",
              "degradation     0\n",
              "subdomain       0\n",
              "domain          0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "domain\n",
              "0    18798\n",
              "1    13994\n",
              "2     1509\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.domain.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cleaned_text</th>\n",
              "      <th>care</th>\n",
              "      <th>harm</th>\n",
              "      <th>fairness</th>\n",
              "      <th>cheating</th>\n",
              "      <th>loyalty</th>\n",
              "      <th>betrayal</th>\n",
              "      <th>authority</th>\n",
              "      <th>subversion</th>\n",
              "      <th>purity</th>\n",
              "      <th>degradation</th>\n",
              "      <th>subdomain</th>\n",
              "      <th>domain</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>France has serious problems with unemployment....</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Conservative</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>You don't understand Marine Le Pen very well. ...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>worldnews</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Just be careful saying that, please. Saying th...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>politics</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Well i'm French so maybe I can help you even t...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>neoliberal</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Worse yet, she called him a misogynist, implyi...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>relationship_advice</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34296</th>\n",
              "      <td>RT @user: Here's the AP's take on :</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Baltimore</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34297</th>\n",
              "      <td>makes the heart hurt -</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>BLM</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34298</th>\n",
              "      <td>Name one, just one Source stating that Macron ...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>worldnews</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34299</th>\n",
              "      <td>Right parties Fillon or Lepen think the coloni...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>europe</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34300</th>\n",
              "      <td>...preach equality not superiority</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>ALM</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>34301 rows \u00d7 13 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            cleaned_text  care  harm  \\\n",
              "0      France has serious problems with unemployment....   0.0   0.0   \n",
              "1      You don't understand Marine Le Pen very well. ...   0.0   0.0   \n",
              "2      Just be careful saying that, please. Saying th...   0.0   1.0   \n",
              "3      Well i'm French so maybe I can help you even t...   0.0   0.0   \n",
              "4      Worse yet, she called him a misogynist, implyi...   0.0   0.0   \n",
              "...                                                  ...   ...   ...   \n",
              "34296                RT @user: Here's the AP's take on :   0.0   0.0   \n",
              "34297                             makes the heart hurt -   0.0   0.0   \n",
              "34298  Name one, just one Source stating that Macron ...   0.0   0.0   \n",
              "34299  Right parties Fillon or Lepen think the coloni...   0.0   1.0   \n",
              "34300                 ...preach equality not superiority   0.0   0.0   \n",
              "\n",
              "       fairness  cheating  loyalty  betrayal  authority  subversion  purity  \\\n",
              "0           0.0       0.0      0.0       0.0        0.0         0.0     0.0   \n",
              "1           1.0       0.0      0.0       0.0        0.0         0.0     0.0   \n",
              "2           0.0       0.0      0.0       0.0        0.0         0.0     0.0   \n",
              "3           0.0       0.0      0.0       0.0        0.0         0.0     0.0   \n",
              "4           0.0       1.0      0.0       0.0        0.0         0.0     0.0   \n",
              "...         ...       ...      ...       ...        ...         ...     ...   \n",
              "34296       0.0       0.0      0.0       0.0        0.0         0.0     0.0   \n",
              "34297       0.0       0.0      0.0       0.0        0.0         0.0     0.0   \n",
              "34298       0.0       0.0      0.0       1.0        0.0         0.0     0.0   \n",
              "34299       0.0       0.0      0.0       0.0        0.0         0.0     0.0   \n",
              "34300       1.0       0.0      0.0       0.0        0.0         0.0     0.0   \n",
              "\n",
              "       degradation            subdomain  domain  \n",
              "0              0.0         Conservative       1  \n",
              "1              0.0            worldnews       1  \n",
              "2              0.0             politics       1  \n",
              "3              0.0           neoliberal       1  \n",
              "4              0.0  relationship_advice       1  \n",
              "...            ...                  ...     ...  \n",
              "34296          0.0            Baltimore       0  \n",
              "34297          0.0                  BLM       0  \n",
              "34298          0.0            worldnews       1  \n",
              "34299          0.0               europe       1  \n",
              "34300          0.0                  ALM       0  \n",
              "\n",
              "[34301 rows x 13 columns]"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFiO7tGDLya-"
      },
      "source": [
        "####\u00a0Text and label values:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "kpVT20CCLya_"
      },
      "outputs": [],
      "source": [
        "text = df.cleaned_text.values\n",
        "labels = df.iloc[:, 1:-2].values # 10 moral dimensions\n",
        "labels2 = df.domain.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>care</th>\n",
              "      <th>harm</th>\n",
              "      <th>fairness</th>\n",
              "      <th>cheating</th>\n",
              "      <th>loyalty</th>\n",
              "      <th>betrayal</th>\n",
              "      <th>authority</th>\n",
              "      <th>subversion</th>\n",
              "      <th>purity</th>\n",
              "      <th>degradation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34296</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34297</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34298</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34299</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34300</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>34301 rows \u00d7 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       care  harm  fairness  cheating  loyalty  betrayal  authority  \\\n",
              "0       0.0   0.0       0.0       0.0      0.0       0.0        0.0   \n",
              "1       0.0   0.0       1.0       0.0      0.0       0.0        0.0   \n",
              "2       0.0   1.0       0.0       0.0      0.0       0.0        0.0   \n",
              "3       0.0   0.0       0.0       0.0      0.0       0.0        0.0   \n",
              "4       0.0   0.0       0.0       1.0      0.0       0.0        0.0   \n",
              "...     ...   ...       ...       ...      ...       ...        ...   \n",
              "34296   0.0   0.0       0.0       0.0      0.0       0.0        0.0   \n",
              "34297   0.0   0.0       0.0       0.0      0.0       0.0        0.0   \n",
              "34298   0.0   0.0       0.0       0.0      0.0       1.0        0.0   \n",
              "34299   0.0   1.0       0.0       0.0      0.0       0.0        0.0   \n",
              "34300   0.0   0.0       1.0       0.0      0.0       0.0        0.0   \n",
              "\n",
              "       subversion  purity  degradation  \n",
              "0             0.0     0.0          0.0  \n",
              "1             0.0     0.0          0.0  \n",
              "2             0.0     0.0          0.0  \n",
              "3             0.0     0.0          0.0  \n",
              "4             0.0     0.0          0.0  \n",
              "...           ...     ...          ...  \n",
              "34296         0.0     0.0          0.0  \n",
              "34297         0.0     0.0          0.0  \n",
              "34298         0.0     0.0          0.0  \n",
              "34299         0.0     0.0          0.0  \n",
              "34300         0.0     0.0          0.0  \n",
              "\n",
              "[34301 rows x 10 columns]"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.iloc[:, 1:-2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1, 2, 0])"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.domain.unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301,
          "referenced_widgets": [
            "06e8a19c0a0541b38a3648b7f149bf6a",
            "1ffb57c39aa246c0b88133f1b51ad509",
            "7bd0123a044f491290f2ff14b6d55c36",
            "0e026a2c581c48509a312cf9d26825d4",
            "484668546d46495da39c648503670d73",
            "e1fe6ac921624ccd827a654e21972403",
            "034414cfee08495fbe3a4aaa11d85adb",
            "c7b312d1e3514b9d977c6385fe214c4b",
            "c8728d5c11c14342afd8babef02ab4ba",
            "d2b1795a5424429fad98a2396e3eceb0",
            "27760a3974084c88a34b998adb2ff594",
            "cd28fc4d177b4abbbc84d985220322d3",
            "efea0bb741f7448baf6d847f5a566ae6",
            "90d556daac7447d8a720aec7718aa393",
            "86df6fbea7ba457c98830f1fff5e04c2",
            "3382b5eb779f4007b2bac46ff84d1dc2",
            "150e3aecfff64468ad941f9d26a5705d",
            "adae4e8339184e888a93f6a28e0494a3",
            "fd46c89cebbf4948ab97a6369cbb571f",
            "4130519be716408d8930a866ba1473b3",
            "5e101b3f726943ac834d8856e69b51ae",
            "90c632921e7547e0a98e579a66b196f0",
            "48638f669d034b85922626738d696a18",
            "ba5ad85660d04485b4a6ca61dc034330",
            "af987ceddcc141a2a89c93127a11f6be",
            "9cebcddef88540bd8acb11eabf6601bf",
            "0ee8c129824245bcb00463e0de3f14e0",
            "79e5574bf6914854956a1e3ab9d0dd91",
            "8f72250de51240ba836884b80fd6b9f5",
            "1b75cb8d663246be9c7c4d0df5ab1b63",
            "783bef901aa947a89bab37cf8a874a03",
            "1152770695604179a5a98a06c4d525e3",
            "277ae2506ba9481c8155f230b5ce4290",
            "8c3a4c94c7b8433f890b783649d6e867",
            "24b9bf9278454be0983b3b8b0435fbaa",
            "cb722da43b9d4b709869d727e71cb32d",
            "0a33d094bd004613a959746b3e64a485",
            "91ed12b162a94125ae8e49d3ed7a4b5f",
            "5866daa3bd82413c894ed224c3ef3f6f",
            "c86af84480944045985b99462a57f8fc",
            "bf1030a82a4f4536b0887f837ed2a7e3",
            "2f6f18fa379e49eea37d8e9cfafc7d91",
            "4e23268863d743bb98393e59b6380e58",
            "a35ec349723c48339d025864a96e6f8a",
            "a5db698c14874c2c8e0b501286f674fc",
            "0ad7cc9a7e634b01a10fd0111a49b33c",
            "fd148bc24e57454b83dc07dc7c3a560a",
            "f1cb53890867466c893b89b2232fead0",
            "b3973cdc12d04893a69ecfffe7b06353",
            "61c09c317cb6415784df597f2d5141ba",
            "2bbf119a82904e65a0f5ae427e8f7912",
            "bcf6e4df9bc547aaa50729d6928e1ec6",
            "df64a6dcf7f445bd82f044a88a2f8313",
            "08d8cc4c76d44842bfb8cd45dc818895",
            "f412088be212468e9f4db1cb6b48c03c"
          ]
        },
        "id": "hlymmArMrCmk",
        "outputId": "a6f88773-7d89-4557-9086-0a56c7037ccf"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "# Tokenizer initialization\n",
        "tokenizer = AutoTokenizer.from_pretrained(base_model)\n",
        "model = AutoModel.from_pretrained(base_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "769aR7FwrCml"
      },
      "outputs": [],
      "source": [
        "# Original Input and attention masks without the augmented dictionary terms:\n",
        "original_input_id = []\n",
        "original_attention_masks = []\n",
        "original_token_type_id = []\n",
        "\n",
        "# Input id and attention masks with the dictionary terms:\n",
        "input_id = []\n",
        "attention_masks = []\n",
        "token_type_id = []\n",
        "\n",
        "def preprocessing(input_text, tokenizer):\n",
        "    '''\n",
        "    Returns <class transformers.tokenization_utils_base.BatchEncoding> with the following fields:\n",
        "    - input_ids: list of token ids\n",
        "    - token_type_ids: list of token type ids\n",
        "    - attention_mask: list of indices (0,1) specifying which tokens should considered by the model (return_attention_mask = True).\n",
        "    '''\n",
        "    return tokenizer.encode_plus(\n",
        "                        input_text,\n",
        "                        add_special_tokens = True,\n",
        "                        max_length = 150,\n",
        "                        padding = 'max_length',\n",
        "                        return_attention_mask = True,\n",
        "                        return_token_type_ids = True,  # Add this line\n",
        "                        return_tensors = 'pt',\n",
        "                        truncation=True\n",
        "                   )\n",
        "\n",
        "for sample in text:\n",
        "    # Original Input\n",
        "    original_encoding_dict = preprocessing(sample, tokenizer)\n",
        "    original_input_id.append(original_encoding_dict['input_ids'])\n",
        "    original_attention_masks.append(original_encoding_dict['attention_mask'])\n",
        "\n",
        "\n",
        "    # Calculate token type ids\n",
        "    original_token_type = torch.zeros_like(original_encoding_dict['input_ids'])\n",
        "    original_token_type[original_encoding_dict['input_ids'] != 0] = 0\n",
        "    original_token_type_id.append(original_token_type)\n",
        "\n",
        "original_input_id = torch.cat(original_input_id, dim=0)\n",
        "original_attention_masks = torch.cat(original_attention_masks, dim=0)\n",
        "original_token_type_id = torch.cat(original_token_type_id, dim = 0)\n",
        "labels = torch.tensor(labels)  # add a new axis at index 1\n",
        "labels2 = torch.tensor(labels2)  # add a new axis at index 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1omKt433rCmm"
      },
      "source": [
        "###\u00a0Test the implementation random inputs:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "original_attention_masks.shape  torch.Size([34301, 150])\n",
            "original_input_id.shape  torch.Size([34301, 150])\n",
            "original_token_type_id.shape  torch.Size([34301, 150])\n"
          ]
        }
      ],
      "source": [
        "print('original_attention_masks.shape ', original_attention_masks.shape)\n",
        "print('original_input_id.shape ', original_input_id.shape)\n",
        "print('original_token_type_id.shape ', original_token_type_id.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OlluCBzorCmo"
      },
      "source": [
        "#### Encode corups for original embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "0zB-6tSWrCmp"
      },
      "outputs": [],
      "source": [
        "def encode_corpus(inputs, attentions, model, batch_size=16):\n",
        "    all_embeddings = []\n",
        "    for start_index in range(0, len(inputs), batch_size):\n",
        "        b_input_ids = inputs[start_index:start_index+batch_size].to(model.device)\n",
        "        b_input_mask = attentions[start_index:start_index+batch_size].to(model.device)\n",
        "        with torch.no_grad():\n",
        "            output = model(b_input_ids,\n",
        "                      token_type_ids = None,\n",
        "                      attention_mask = b_input_mask).last_hidden_state[:,0,:].detach().cpu()\n",
        "            all_embeddings.extend(output)\n",
        "    return torch.stack(all_embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "fECGi0p3rCmp",
        "outputId": "487562b9-f041-4840-8f26-e568e3983247"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([34301, 10])\n",
            "torch.Size([34301])\n"
          ]
        }
      ],
      "source": [
        "print(labels.shape)\n",
        "print(labels2.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "9vZum_KarCmq"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qSzQrOiTrCmq"
      },
      "source": [
        "### Doman Adversarial Function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "1WmSf5SGLybC"
      },
      "outputs": [],
      "source": [
        "class GradientReversal(Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, x, alpha):\n",
        "        ctx.save_for_backward(x, alpha)\n",
        "        return x\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        grad_input = None\n",
        "        _, alpha = ctx.saved_tensors\n",
        "        if ctx.needs_input_grad[0]:\n",
        "            grad_input = - alpha*grad_output\n",
        "        return grad_input, None\n",
        "revgrad = GradientReversal.apply\n",
        "\n",
        "class GradientReversal(nn.Module):\n",
        "    def __init__(self, alpha):\n",
        "        super().__init__()\n",
        "        self.alpha = torch.tensor(alpha, requires_grad=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return revgrad(x, self.alpha)\n",
        "\n",
        "class AdversarialBERT(nn.Module):\n",
        "    def __init__(self, bert_model, moral_label=5, domain_label=2, class_weight=[1,1],\n",
        "                 domain_weight=1, identity_weight=1, reconstruction_weight=1, moral_weight=1,\n",
        "                 alpha=1.0,\n",
        "                 freeze_bert=False): # class_weight[0] = -1 deactivates the baalancing tentatives\n",
        "\n",
        "        super(AdversarialBERT, self).__init__()\n",
        "        self.bert = bert_model\n",
        "        bert_dim = 768\n",
        "        self.invariant_trans = nn.Linear(768, 768)\n",
        "        print(' self.invariant_trans ',  self.invariant_trans)\n",
        "        if identity_weight+reconstruction_weight+domain_weight==0:\n",
        "            self.moral_classification = nn.Linear(768, moral_label)\n",
        "        else:\n",
        "            self.moral_classification = nn.Sequential(nn.Linear(768,768),\n",
        "                                                      nn.ReLU(),\n",
        "                                                      nn.Linear(768, moral_label))\n",
        "\n",
        "        self.domain_classification = nn.Sequential(GradientReversal(alpha),\n",
        "                                                   nn.Linear(768,768),\n",
        "                                                   nn.ReLU(),\n",
        "                                                   nn.Dropout(0.3),\n",
        "                                                   nn.Linear(768, domain_label))\n",
        "\n",
        "        # Dynamically adjustable alpha for gradient reversal\n",
        "        self.alpha = alpha\n",
        "        self.domain_weight = domain_weight\n",
        "\n",
        "        if moral_label>2:\n",
        "                self.loss_fn_moral = FocalLoss(logits=True) #nn.BCEWithLogitsLoss() #nn.CrossEntropyLoss()\n",
        "\n",
        "        else:\n",
        "            if class_weight[0]>0:\n",
        "                weights = torch.tensor(class_weight).float()\n",
        "            else:\n",
        "                weights = torch.tensor([1.0 for _ in range(moral_label)]).float()\n",
        "            if moral_label>2:\n",
        "                self.loss_fn_moral = FocalLoss(logits=True) #nn.BCEWithLogitsLoss(pos_weight=weights) #BCEWithLogitsLoss\n",
        "\n",
        "            else:\n",
        "                self.loss_fn_moral = nn.CrossEntropyLoss(weight=weights) # FocalLoss(logits=True)\n",
        "\n",
        "        self.loss_fn_domain = nn.CrossEntropyLoss()\n",
        "        self.reconstruction_feed = nn.Linear(768, 768)\n",
        "        self.loss_reconstruction = nn.MSELoss()\n",
        "        self.weight_identity = identity_weight\n",
        "        self.reconstruction_weight = reconstruction_weight\n",
        "        self.moral_weight = moral_weight\n",
        "        self.identity = torch.eye(768).to(device)\n",
        "        self.freeze=freeze_bert\n",
        "\n",
        "    def update_alpha(self, new_alpha):\n",
        "        # Method to update alpha for the gradient reversal layer\n",
        "        self.domain_classification[0].alpha = new_alpha\n",
        "\n",
        "    def update_model_params(self, domain_weight, moral_weight, reconstruction_weight, identity_weight):\n",
        "        # Update the relevant parameters\n",
        "        self.domain_weight = domain_weight\n",
        "        self.moral_weight = moral_weight\n",
        "        self.reconstruction_weight = reconstruction_weight\n",
        "        self.identity_weight = identity_weight\n",
        "\n",
        "    def forward(self, b_input_ids, b_token_type_ids, b_input_mask, b_labels, b_domain_labels, original_bert_embeddings=None, test=False):\n",
        "        # Forward pass\n",
        "        if self.freeze:\n",
        "            with torch.no_grad():\n",
        "                pooled_output = self.bert(b_input_ids,\n",
        "                                    token_type_ids = b_token_type_ids, #it was None\n",
        "                                    attention_mask = b_input_mask).last_hidden_state[:,0,:]\n",
        "\n",
        "        else:\n",
        "            pooled_output = self.bert(b_input_ids,\n",
        "                                token_type_ids = b_token_type_ids, #it was None\n",
        "                                attention_mask = b_input_mask).last_hidden_state[:,0,:]\n",
        "\n",
        "\n",
        "        pooled_output = self.invariant_trans(pooled_output)\n",
        "#         print('transformed_output with without Attention ',combined_output.shape)\n",
        "\n",
        "\n",
        "        logits = self.moral_classification(pooled_output)\n",
        "#         print(f\"Logits shape: {logits.shape}, Labels shape: {b_labels.float().shape}\")\n",
        "\n",
        "        loss_moral = self.loss_fn_moral(logits, b_labels)\n",
        "\n",
        "        if test:\n",
        "            return loss_moral, logits\n",
        "        if self.domain_weight>0:\n",
        "            loss_domain = self.loss_fn_domain(self.domain_classification(pooled_output), b_domain_labels)\n",
        "        else:\n",
        "            loss_domain=0\n",
        "        if original_bert_embeddings is not None:\n",
        "            loss_reconstruction = self.loss_reconstruction(self.reconstruction_feed(pooled_output), original_bert_embeddings)*self.reconstruction_weight\n",
        "        else:\n",
        "            loss_reconstruction=0\n",
        "        if self.weight_identity>0:\n",
        "            loss_identity = torch.norm(self.invariant_trans.weight-self.identity)*self.weight_identity\n",
        "        else:\n",
        "            loss_identity=0\n",
        "        total_loss = loss_moral*self.moral_weight+loss_reconstruction+loss_identity+self.domain_weight*loss_domain\n",
        "        return  total_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-3r0HHGCWov"
      },
      "source": [
        "# Single Label Experiments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "SixTxhkfXCDL"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "_tuned_with_twitter_FB_posts_MFT_10\n"
          ]
        }
      ],
      "source": [
        "batch_size = 16\n",
        "\n",
        "def adjust_domain_label(labels, test_domain):\n",
        "    return torch.tensor([l if l<test_domain else l-1 for l in labels.tolist()])\n",
        "\n",
        "test_domain = True\n",
        "\n",
        "if test_domain:\n",
        "  test_domain = 1 # Change this for testing in different domains\n",
        "  train_idx = df[df.domain!=test_domain].index\n",
        "  val_idx = df[df.domain==test_domain].index\n",
        "\n",
        "if test_domain==0:\n",
        "  suffix=\"_tuned_with_reddit_FB_posts_MFT_10\"\n",
        "  print(suffix)  \n",
        "elif test_domain==1:\n",
        "  suffix=\"_tuned_with_twitter_FB_posts_MFT_10\"\n",
        "  print(suffix)  \n",
        "elif test_domain==2:\n",
        "  suffix=\"_tuned_with_twitter_reddit_posts_MFT_10\"\n",
        "  print(suffix)  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTuGRnJ85n5P"
      },
      "source": [
        "### Training:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153,
          "referenced_widgets": [
            "4cdb28ad2e9545a189e100ca02d02205",
            "9c94fcb097734364b54dfede72d735f8",
            "9944266adc3940728af07f08dd17c311",
            "855ff82945b2419ab7c7672ef2211716",
            "849880be758c44378637ec6925d98dec",
            "c1e0037bafef481b844db983d59af3a5",
            "c931130302454bf3bc2623d388ac4560",
            "07d2772d747f492fb9a2aa6d4471a7d8",
            "125c7442d5764e58a1e14607a5031d36",
            "0cdfc4d9b1304cce89d70f145fc946d1",
            "2488e56d59cd4b8e832759c857b93c62"
          ]
        },
        "id": "E4WFsLFtCWAJ",
        "outputId": "28033011-192a-4019-f09e-c6136c6449af"
      },
      "outputs": [],
      "source": [
        "# Initialize scaler for mixed precision training\n",
        "scaler = GradScaler()\n",
        "\n",
        "\n",
        "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
        "\n",
        "possible_labels = [\"care\", \"harm\", \"fairness\", \"cheating\", \"loyalty\", \"betrayal\",\n",
        "                   \"authority\", \"subversion\", \"purity\", \"degradation\"]\n",
        "\n",
        "bert_original_embeddings = None\n",
        "adversarial = True\n",
        "\n",
        "for lab_idx, lab in enumerate(possible_labels):\n",
        "#     if lab not in [\"betrayal\"]:\n",
        "#         continue\n",
        "    best_f1 = 0\n",
        "\n",
        "    num_labels = 2\n",
        "    num_domains = 2\n",
        " \n",
        "    print(f\"Number of Domains: {num_domains}\")\n",
        "\n",
        "    epochs = 5\n",
        "    batch_size = 16\n",
        "    epoch_count = 0\n",
        "    rw =0.1\n",
        "    iw = 0.01\n",
        "    dw = 0.1\n",
        "    \n",
        "    # for parameter_tuple in list(product([0.1, 0.5], [0.01, 0.5], [0.1, 1])):\n",
        "    #     rw, iw, dw = parameter_tuple  # Assuming rw, iw, dw correspond to the elements in the parameter tuple\n",
        "\n",
        "    # Initialize the model with dynamic alpha for gradient reversal\n",
        "    initial_alpha = 0.1\n",
        "    alpha_growth_rate = 0.1  # How much to increase alpha after each epoch\n",
        "\n",
        "    print('Models for predicting 10 Moral Dimensions with BERT Base')\n",
        "    print(f'Parameters: reconstruction_weight = {rw}; identity_weight = {iw}; domain_weight = {dw}.')\n",
        "\n",
        "    bert_model = AutoModel.from_pretrained(base_model).cuda()\n",
        "    \n",
        "    if bert_original_embeddings is None:\n",
        "        bert_original_embeddings = encode_corpus(original_input_id[train_idx],\n",
        "                                                 original_attention_masks[train_idx],\n",
        "                                                 bert_model)\n",
        "        \n",
        "\n",
        "    bert_model = bert_model.to(\"cuda\")\n",
        "    new_labels = []\n",
        "\n",
        "    for ex in labels[train_idx]:\n",
        "        if ex[lab_idx]:\n",
        "            new_labels.append(1)\n",
        "        else:\n",
        "            new_labels.append(0)\n",
        "\n",
        "    \n",
        "    pos_weight = [sum(new_labels), len(new_labels)]\n",
        "\n",
        "    train_set = TensorDataset(original_input_id[train_idx],\n",
        "                              original_token_type_id[train_idx],\n",
        "                              original_attention_masks[train_idx],\n",
        "                              torch.tensor(new_labels),\n",
        "                              adjust_domain_label(labels2[train_idx], test_domain),\n",
        "                              bert_original_embeddings)\n",
        "\n",
        "    new_labels = []\n",
        "\n",
        "    for ex in labels[val_idx]:\n",
        "        if ex[lab_idx]:\n",
        "            new_labels.append(1)\n",
        "        else:\n",
        "            new_labels.append(0)\n",
        "\n",
        "    val_set = TensorDataset(original_input_id[val_idx],\n",
        "                            original_token_type_id[val_idx],\n",
        "                            original_attention_masks[val_idx],\n",
        "                            torch.tensor(new_labels),\n",
        "                            labels2[val_idx])\n",
        "\n",
        "    pos_weight = pos_weight[0] / pos_weight[1]\n",
        "    class_weight = [pos_weight, 1 - pos_weight]\n",
        "    \n",
        "    # Prepare DataLoader\n",
        "    train_dataloader = DataLoader(\n",
        "        train_set,\n",
        "        sampler=RandomSampler(train_set),\n",
        "        batch_size=batch_size\n",
        "    )\n",
        "\n",
        "    validation_dataloader = DataLoader(\n",
        "        val_set,\n",
        "        batch_size=batch_size\n",
        "    )\n",
        "\n",
        "    total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "    def pick_the_model(adversarial, model, class_weight, epoch):\n",
        "        \n",
        "        if adversarial:\n",
        "            print('Adversarial', adversarial)\n",
        "            model.update_model_params(domain_weight=dw, moral_weight=1,\n",
        "                                      reconstruction_weight=rw, identity_weight=iw)\n",
        "        else:\n",
        "            model.update_model_params(domain_weight=0, moral_weight=1,\n",
        "                                      reconstruction_weight=0, identity_weight=0)\n",
        "            print('Adversarial', adversarial)\n",
        "        model = model.to(device)\n",
        "        return model\n",
        "\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "   \n",
        "    # Initialize the base model outside of the training loop.\n",
        "    model = AdversarialBERT(bert_model, moral_label=num_labels,\n",
        "                            domain_label=num_domains, domain_weight=dw, moral_weight=0.5,\n",
        "                            reconstruction_weight=rw, identity_weight=iw,\n",
        "                            alpha=initial_alpha, class_weight=class_weight,\n",
        "                            freeze_bert=False).to(device)\n",
        "\n",
        "    optimizer = torch.optim.AdamW(model.parameters(),  lr = 1e-5)\n",
        "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
        "\n",
        "    for epoch in trange(epochs, desc='Epoch'):\n",
        "        print('Epoch: ', epoch)\n",
        "        model = pick_the_model(adversarial, model, class_weight, epoch)\n",
        "        model.train()\n",
        "        current_alpha = torch.tensor(initial_alpha + alpha_growth_rate * epoch, requires_grad=False).to(device)\n",
        "        model.update_alpha(current_alpha)  \n",
        "\n",
        "        tr_loss, nb_tr_examples, nb_tr_steps = 0, 0, 0\n",
        "\n",
        "        for step, batch in enumerate(train_dataloader):\n",
        "            batch = tuple(t.to(device) for t in batch)\n",
        "            b_input_ids, b_token_type_ids, b_input_mask, b_labels, b_domain_labels, bert_embeddings = batch\n",
        "            optimizer.zero_grad()\n",
        "            loss = model(b_input_ids, b_token_type_ids, b_input_mask, b_labels, b_domain_labels, bert_embeddings)\n",
        "            \n",
        "            scheduler.step()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            tr_loss += loss.item()\n",
        "            nb_tr_examples += b_input_ids.size(0)\n",
        "            nb_tr_steps += 1\n",
        "\n",
        "        # Validation step\n",
        "        model.eval()\n",
        "        val_loss, nb_val_examples, nb_val_steps = 0, 0, 0\n",
        "        y_true, y_pred, logits_list = [], [],[]\n",
        "\n",
        "        for batch in validation_dataloader:\n",
        "            batch = tuple(t.to(device) for t in batch)\n",
        "            b_input_ids, b_token_type_ids, b_input_mask, b_labels, b_domain_labels = batch\n",
        "\n",
        "            with torch.no_grad():\n",
        "                with autocast():\n",
        "                    loss, logits = model(b_input_ids, b_token_type_ids, b_input_mask, b_labels, b_domain_labels, test=True)\n",
        "\n",
        "                val_loss += loss.item()\n",
        "                logits = logits.detach().cpu().numpy()\n",
        "                nb_val_examples += b_input_ids.size(0)\n",
        "                nb_val_steps += 1\n",
        "                label_ids = b_labels.to('cpu').numpy()\n",
        "                predicted_labels = np.argmax(logits, axis=1)\n",
        "                y_true.extend(label_ids)\n",
        "                y_pred.extend(predicted_labels)\n",
        "                logits_list.extend(logits)\n",
        "            \n",
        "\n",
        "        epoch_count = epoch_count + 1\n",
        "        \n",
        "        \n",
        "        \n",
        "        print('Evaluation')\n",
        "      \n",
        "        # Single-LABEL CLASSIFICATION REPORT\n",
        "        #################################\n",
        "        target_names = [f\"Non-{lab}\", lab]\n",
        "        report = classification_report(y_true, y_pred, target_names=target_names)\n",
        "        f1 = f1_score(y_true, y_pred, average=\"binary\")\n",
        "        print('F1 score', f1)\n",
        "        print(\"\\nClassification Report:\")\n",
        "        print(report)\n",
        "        #################################\n",
        "\n",
        "        if f1 > best_f1:\n",
        "            best_f1 = f1\n",
        "            print('best_F1', best_f1)\n",
        "            print(\"We are saving the state of this model\")\n",
        "            torch.save(model.state_dict(), f\"path/to/saved_models/{lab}{suffix}.bin\")\n",
        "\n",
        "        try:\n",
        "            print('\\n\\t - Train loss: {:.4f}'.format(tr_loss / nb_tr_steps))\n",
        "            print('\\t - Validation loss: {:.4f}'.format(val_loss / nb_val_steps))\n",
        "\n",
        "        except ZeroDivisionError:\n",
        "            print(\"No predicted positives...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JOPjet2IhSf9"
      },
      "source": [
        "# Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_df =df[df['domain']==1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(13994, 13)"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [],
      "source": [
        "# pd.merge(test_df, lib_opp, how = 'inner', on = 'text')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "base_model = \"bert-base-uncased\"\n",
        "\n",
        "input_files = test_df[\"cleaned_text\"].values\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(base_model)\n",
        "bert_model = AutoModel.from_pretrained(base_model)\n",
        "\n",
        "# Original Input and attention masks without the augmented dictionary terms:\n",
        "original_input_id = []\n",
        "original_attention_masks = []\n",
        "original_token_type_id = []\n",
        "\n",
        "# Input id and attention masks with the dictionary terms:\n",
        "input_id = []\n",
        "attention_masks = []\n",
        "token_type_id = []\n",
        "\n",
        "def preprocessing(input_text, tokenizer):\n",
        "    '''\n",
        "    Returns <class transformers.tokenization_utils_base.BatchEncoding> with the following fields:\n",
        "    - input_ids: list of token ids\n",
        "    - token_type_ids: list of token type ids\n",
        "    - attention_mask: list of indices (0,1) specifying which tokens should considered by the model (return_attention_mask = True).\n",
        "    '''\n",
        "    return tokenizer.encode_plus(\n",
        "                        input_text,\n",
        "                        add_special_tokens = True,\n",
        "                        max_length = 150,\n",
        "                        padding = 'max_length',\n",
        "                        return_attention_mask = True,\n",
        "                        return_token_type_ids = True,  # Add this line\n",
        "                        return_tensors = 'pt',\n",
        "                        truncation=True\n",
        "                   )\n",
        "\n",
        "for sample in input_files:\n",
        "    # Original Input\n",
        "    original_encoding_dict = preprocessing(sample, tokenizer)\n",
        "    original_input_id.append(original_encoding_dict['input_ids'])\n",
        "    original_attention_masks.append(original_encoding_dict['attention_mask'])\n",
        "\n",
        "\n",
        "    # Calculate token type ids\n",
        "    original_token_type = torch.zeros_like(original_encoding_dict['input_ids'])\n",
        "    original_token_type[original_encoding_dict['input_ids'] != 0] = 0\n",
        "\n",
        "    original_token_type_id.append(original_token_type)\n",
        "\n",
        "original_input_id = torch.cat(original_input_id, dim=0)\n",
        "original_attention_masks = torch.cat(original_attention_masks, dim=0)\n",
        "original_token_type_id = torch.cat(original_token_type_id, dim = 0)\n",
        "\n",
        "labels = test_df.loc[:, \"care\":\"degradation\"].values\n",
        "labels2 = torch.tensor([0 for _ in range(len(input_files))])  # add a new axis at index 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'_tuned_with_reddit_FB_posts_MFT_10'"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "suffix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            "Evaluation\n",
            "best threshold: 0.7000000000000001\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Non-care       0.97      0.96      0.96     13257\n",
            "        care       0.34      0.41      0.37       737\n",
            "\n",
            "    accuracy                           0.93     13994\n",
            "   macro avg       0.66      0.68      0.67     13994\n",
            "weighted avg       0.93      0.93      0.93     13994\n",
            "\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            "Evaluation\n",
            "best threshold: 0.55\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Non-harm       0.96      0.90      0.93     12980\n",
            "        harm       0.30      0.58      0.40      1014\n",
            "\n",
            "    accuracy                           0.87     13994\n",
            "   macro avg       0.63      0.74      0.66     13994\n",
            "weighted avg       0.92      0.87      0.89     13994\n",
            "\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            "Evaluation\n",
            "best threshold: 0.35000000000000003\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "Non-fairness       0.96      0.91      0.94     13371\n",
            "    fairness       0.13      0.29      0.18       623\n",
            "\n",
            "    accuracy                           0.88     13994\n",
            "   macro avg       0.55      0.60      0.56     13994\n",
            "weighted avg       0.93      0.88      0.90     13994\n",
            "\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            "Evaluation\n",
            "best threshold: 0.7500000000000001\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "Non-cheating       0.95      0.93      0.94     13153\n",
            "    cheating       0.20      0.28      0.24       841\n",
            "\n",
            "    accuracy                           0.89     13994\n",
            "   macro avg       0.58      0.60      0.59     13994\n",
            "weighted avg       0.91      0.89      0.90     13994\n",
            "\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            "Evaluation\n",
            "best threshold: 0.8500000000000001\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "Non-betrayal       0.99      0.99      0.99     13806\n",
            "    betrayal       0.32      0.18      0.23       188\n",
            "\n",
            "    accuracy                           0.98     13994\n",
            "   macro avg       0.65      0.59      0.61     13994\n",
            "weighted avg       0.98      0.98      0.98     13994\n",
            "\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            "Evaluation\n",
            "best threshold: 0.55\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "Non-authority       0.98      0.95      0.96     13664\n",
            "    authority       0.09      0.20      0.12       330\n",
            "\n",
            "     accuracy                           0.93     13994\n",
            "    macro avg       0.53      0.58      0.54     13994\n",
            " weighted avg       0.96      0.93      0.94     13994\n",
            "\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            "Evaluation\n",
            "best threshold: 0.7500000000000001\n",
            "\n",
            "Classification Report:\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "Non-subversion       0.98      0.98      0.98     13637\n",
            "    subversion       0.21      0.24      0.22       357\n",
            "\n",
            "      accuracy                           0.96     13994\n",
            "     macro avg       0.59      0.61      0.60     13994\n",
            "  weighted avg       0.96      0.96      0.96     13994\n",
            "\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            "Evaluation\n",
            "best threshold: 0.4\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Non-purity       0.99      0.99      0.99     13894\n",
            "      purity       0.10      0.19      0.13       100\n",
            "\n",
            "    accuracy                           0.98     13994\n",
            "   macro avg       0.55      0.59      0.56     13994\n",
            "weighted avg       0.99      0.98      0.99     13994\n",
            "\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            " self.invariant_trans  Linear(in_features=768, out_features=768, bias=True)\n",
            "Evaluation\n",
            "best threshold: 0.6000000000000001\n",
            "\n",
            "Classification Report:\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "Non-degradation       0.99      0.99      0.99     13807\n",
            "    degradation       0.34      0.39      0.36       187\n",
            "\n",
            "       accuracy                           0.98     13994\n",
            "      macro avg       0.66      0.69      0.67     13994\n",
            "   weighted avg       0.98      0.98      0.98     13994\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "possible_labels = [\"care\", \"harm\", \"fairness\", \"cheating\", \"loyalty\", \"betrayal\",\n",
        "                   \"authority\", \"subversion\", \"purity\", \"degradation\"]\n",
        "predictions = []\n",
        "\n",
        "for lab_idx, lab in enumerate(possible_labels):\n",
        "    best_f1 = 0\n",
        "\n",
        "    for th in np.arange(0.05, 1, 0.05): # This allows for a customisable threshold; use 0.5 for a standard threshold.\n",
        "\n",
        "        new_labels = []\n",
        "        for ex in labels:\n",
        "            if ex[lab_idx]:\n",
        "                new_labels.append(1)\n",
        "            else:\n",
        "                new_labels.append(0)\n",
        "\n",
        "        val_set = TensorDataset(original_input_id,\n",
        "                                original_token_type_id,\n",
        "                                original_attention_masks,\n",
        "                                torch.tensor(new_labels),\n",
        "                                labels2)\n",
        "\n",
        "        validation_dataloader = DataLoader(\n",
        "            val_set,\n",
        "            batch_size=batch_size\n",
        "        )\n",
        "\n",
        "        # Run the models from the checkpoints\n",
        "        checkpoint_folder = f\"Path/to/MoralBERT/Checkpoints/\"\n",
        "        model_checkpoint = f\"{checkpoint_folder}model_bert_{lab}{suffix}.bin\"\n",
        "\n",
        "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "        # Initialize the base model outside of the training loop.\n",
        "        model = AdversarialBERT(bert_model, moral_label=num_labels,\n",
        "                                domain_label=num_domains, domain_weight=dw, moral_weight=1,\n",
        "                                reconstruction_weight=rw, identity_weight=iw,\n",
        "                                alpha=0, class_weight=[0, 0],\n",
        "                                freeze_bert=False).to(device)\n",
        "\n",
        "        model.load_state_dict(torch.load(model_checkpoint))\n",
        "\n",
        "        ex_id = 0\n",
        "\n",
        "        model.eval()\n",
        "        val_loss, nb_val_examples, nb_val_steps = 0, 0, 0\n",
        "        y_true, y_pred = [], []\n",
        "\n",
        "        for batch in validation_dataloader:\n",
        "            batch = tuple(t.to(device) for t in batch)\n",
        "            b_input_ids, b_token_type_ids, b_input_mask, b_labels, b_domain_labels = batch\n",
        "\n",
        "            with torch.no_grad():\n",
        "                loss, logits = model(b_input_ids, b_token_type_ids, b_input_mask, b_labels, b_domain_labels, test=True)\n",
        "\n",
        "                val_loss += loss.item()\n",
        "                logits = logits.detach().cpu().numpy()\n",
        "                nb_val_examples += b_input_ids.size(0)\n",
        "                nb_val_steps += 1\n",
        "                label_ids = b_labels.to('cpu').numpy()\n",
        "                predicted_labels = [l[1] > th for l in softmax(logits, axis=1)]\n",
        "                y_true.extend(label_ids)\n",
        "                y_pred.extend(predicted_labels)\n",
        "\n",
        "        f1 = f1_score(y_true, y_pred, average=\"binary\")\n",
        "        if f1 > best_f1:\n",
        "            best_f1 = f1\n",
        "            best_y = y_pred.copy()\n",
        "            best_th = th\n",
        "\n",
        "    if not lab_idx:\n",
        "        for l, g in zip(best_y, y_true):\n",
        "            predictions.append({\"pred_\" + lab: l, \"true_\" + lab: g, \"id\": ex_id})\n",
        "            ex_id += 1\n",
        "    else:\n",
        "        for l, g in zip(best_y, y_true):\n",
        "            predictions[ex_id][\"pred_\" + lab] = l\n",
        "            predictions[ex_id][\"true_\" + lab] = g\n",
        "            ex_id += 1\n",
        "\n",
        "    print('Evaluation')\n",
        "\n",
        "    # Single-LABEL CLASSIFICATION REPORT\n",
        "    #################################\n",
        "    print(f\"best threshold: {best_th}\")\n",
        "    target_names = [f\"Non-{lab}\", lab]\n",
        "    report = classification_report(y_true, best_y, target_names=target_names)\n",
        "    f1 = f1_score(y_true, best_y, average=\"binary\")\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(report)\n",
        "    #################################\n",
        "\n",
        "pred_df = pd.DataFrame(predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [],
      "source": [
        "pd.set_option('display.max_columns', None)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [],
      "source": [
        "results = []\n",
        "\n",
        "for idx_lab, lab in enumerate(possible_labels):\n",
        "    result = {\"Moral Value\":lab}\n",
        "    true = test_df[lab].values\n",
        "    candidate = pred_df[\"pred_\"+lab].values\n",
        "\n",
        "    result[\"F1 Score (Binary)\"] = f1_score(true, candidate, average=\"binary\")\n",
        "    result[\"F1 Score (Weighted)\"] = f1_score(true, candidate, average=\"weighted\")\n",
        "\n",
        "    result[\"Precision Score (Binary)\"] = precision_score(true, candidate, average=\"binary\")\n",
        "    result[\"Precision Score (Weighted)\"] = precision_score(true, candidate, average=\"weighted\")\n",
        "\n",
        "    result[\"Recall Score (Binary)\"] = recall_score(true, candidate, average=\"binary\")\n",
        "    result[\"Recall Score (Weighted)\"] = recall_score(true, candidate, average=\"weighted\")\n",
        "\n",
        "    result[\"Accuracy\"] = accuracy_score(true, candidate)\n",
        "\n",
        "    results.append(result)\n",
        "\n",
        "results = pd.DataFrame(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Moral Value</th>\n",
              "      <th>F1 Score (Binary)</th>\n",
              "      <th>F1 Score (Weighted)</th>\n",
              "      <th>Precision Score (Binary)</th>\n",
              "      <th>Precision Score (Weighted)</th>\n",
              "      <th>Recall Score (Binary)</th>\n",
              "      <th>Recall Score (Weighted)</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>care</td>\n",
              "      <td>0.373762</td>\n",
              "      <td>0.930666</td>\n",
              "      <td>0.343572</td>\n",
              "      <td>0.934008</td>\n",
              "      <td>0.409769</td>\n",
              "      <td>0.927683</td>\n",
              "      <td>0.927683</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>harm</td>\n",
              "      <td>0.399594</td>\n",
              "      <td>0.890806</td>\n",
              "      <td>0.304281</td>\n",
              "      <td>0.916965</td>\n",
              "      <td>0.581854</td>\n",
              "      <td>0.873303</td>\n",
              "      <td>0.873303</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>fairness</td>\n",
              "      <td>0.180109</td>\n",
              "      <td>0.902528</td>\n",
              "      <td>0.130186</td>\n",
              "      <td>0.927824</td>\n",
              "      <td>0.292135</td>\n",
              "      <td>0.881592</td>\n",
              "      <td>0.881592</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>cheating</td>\n",
              "      <td>0.236181</td>\n",
              "      <td>0.899144</td>\n",
              "      <td>0.204526</td>\n",
              "      <td>0.907852</td>\n",
              "      <td>0.279429</td>\n",
              "      <td>0.891382</td>\n",
              "      <td>0.891382</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>loyalty</td>\n",
              "      <td>0.215962</td>\n",
              "      <td>0.974588</td>\n",
              "      <td>0.248649</td>\n",
              "      <td>0.973182</td>\n",
              "      <td>0.190871</td>\n",
              "      <td>0.976133</td>\n",
              "      <td>0.976133</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>betrayal</td>\n",
              "      <td>0.226027</td>\n",
              "      <td>0.981552</td>\n",
              "      <td>0.317308</td>\n",
              "      <td>0.979819</td>\n",
              "      <td>0.175532</td>\n",
              "      <td>0.983850</td>\n",
              "      <td>0.983850</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>authority</td>\n",
              "      <td>0.123162</td>\n",
              "      <td>0.944694</td>\n",
              "      <td>0.088391</td>\n",
              "      <td>0.959101</td>\n",
              "      <td>0.203030</td>\n",
              "      <td>0.931828</td>\n",
              "      <td>0.931828</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>subversion</td>\n",
              "      <td>0.220762</td>\n",
              "      <td>0.958897</td>\n",
              "      <td>0.207921</td>\n",
              "      <td>0.960217</td>\n",
              "      <td>0.235294</td>\n",
              "      <td>0.957625</td>\n",
              "      <td>0.957625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>purity</td>\n",
              "      <td>0.134752</td>\n",
              "      <td>0.985073</td>\n",
              "      <td>0.104396</td>\n",
              "      <td>0.987778</td>\n",
              "      <td>0.190000</td>\n",
              "      <td>0.982564</td>\n",
              "      <td>0.982564</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>degradation</td>\n",
              "      <td>0.359102</td>\n",
              "      <td>0.982244</td>\n",
              "      <td>0.336449</td>\n",
              "      <td>0.982899</td>\n",
              "      <td>0.385027</td>\n",
              "      <td>0.981635</td>\n",
              "      <td>0.981635</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Moral Value  F1 Score (Binary)  F1 Score (Weighted)  \\\n",
              "0         care           0.373762             0.930666   \n",
              "1         harm           0.399594             0.890806   \n",
              "2     fairness           0.180109             0.902528   \n",
              "3     cheating           0.236181             0.899144   \n",
              "4      loyalty           0.215962             0.974588   \n",
              "5     betrayal           0.226027             0.981552   \n",
              "6    authority           0.123162             0.944694   \n",
              "7   subversion           0.220762             0.958897   \n",
              "8       purity           0.134752             0.985073   \n",
              "9  degradation           0.359102             0.982244   \n",
              "\n",
              "   Precision Score (Binary)  Precision Score (Weighted)  \\\n",
              "0                  0.343572                    0.934008   \n",
              "1                  0.304281                    0.916965   \n",
              "2                  0.130186                    0.927824   \n",
              "3                  0.204526                    0.907852   \n",
              "4                  0.248649                    0.973182   \n",
              "5                  0.317308                    0.979819   \n",
              "6                  0.088391                    0.959101   \n",
              "7                  0.207921                    0.960217   \n",
              "8                  0.104396                    0.987778   \n",
              "9                  0.336449                    0.982899   \n",
              "\n",
              "   Recall Score (Binary)  Recall Score (Weighted)  Accuracy  \n",
              "0               0.409769                 0.927683  0.927683  \n",
              "1               0.581854                 0.873303  0.873303  \n",
              "2               0.292135                 0.881592  0.881592  \n",
              "3               0.279429                 0.891382  0.891382  \n",
              "4               0.190871                 0.976133  0.976133  \n",
              "5               0.175532                 0.983850  0.983850  \n",
              "6               0.203030                 0.931828  0.931828  \n",
              "7               0.235294                 0.957625  0.957625  \n",
              "8               0.190000                 0.982564  0.982564  \n",
              "9               0.385027                 0.981635  0.981635  "
            ]
          },
          "execution_count": 80,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Bootstraping:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {},
      "outputs": [],
      "source": [
        "possible_labels = [\"care\", \"harm\", \"fairness\", \"cheating\", \"loyalty\", \"betrayal\",\n",
        "                   \"authority\", \"subversion\", \"purity\", \"degradation\"]\n",
        "\n",
        "\n",
        "test_df.reset_index(drop = True, inplace = True)\n",
        "n_bootstrap_iters = 1000  # Number of bootstrap iterations\n",
        "bootstrap_results = {label: {metric: [] for metric in [\"F1 (Binary)\",  \"F1 (Macro)\", \"F1 (Weighted)\",\n",
        "                                                       \"Precision (Binary)\", \"Precision (Macro)\", \"Precision (Weighted)\",\n",
        "                                                       \"Recall (Binary)\", \"Recall (Macro)\", \"Recall (Weighted)\", \"Accuracy\"]} for label in possible_labels}\n",
        "\n",
        "for _ in range(n_bootstrap_iters):\n",
        "    for lab in possible_labels:\n",
        "        # resampling with replacement\n",
        "        sample_indices = resample(np.arange(len(test_df)), replace=True)\n",
        "        true = test_df.loc[sample_indices, lab].values\n",
        "        candidate = pred_df.loc[sample_indices, f\"pred_{lab}\"].values\n",
        "        \n",
        "        # computing metrics for bootstrap sample\n",
        "        bootstrap_results[lab][\"F1 (Binary)\"].append(f1_score(true, candidate, average=\"binary\", zero_division=0))\n",
        "        bootstrap_results[lab][\"F1 (Macro)\"].append(f1_score(true, candidate, average=\"macro\", zero_division=0))\n",
        "        bootstrap_results[lab][\"F1 (Weighted)\"].append(f1_score(true, candidate, average=\"weighted\", zero_division=0))\n",
        "        bootstrap_results[lab][\"Precision (Binary)\"].append(precision_score(true, candidate, average=\"binary\", zero_division=0))\n",
        "        bootstrap_results[lab][\"Precision (Macro)\"].append(precision_score(true, candidate, average=\"macro\", zero_division=0))\n",
        "        bootstrap_results[lab][\"Precision (Weighted)\"].append(precision_score(true, candidate, average=\"weighted\", zero_division=0))\n",
        "        bootstrap_results[lab][\"Recall (Binary)\"].append(recall_score(true, candidate, average=\"binary\", zero_division=0))\n",
        "        bootstrap_results[lab][\"Recall (Macro)\"].append(recall_score(true, candidate, average=\"macro\", zero_division=0))\n",
        "        bootstrap_results[lab][\"Recall (Weighted)\"].append(recall_score(true, candidate, average=\"weighted\", zero_division=0))\n",
        "        bootstrap_results[lab][\"Accuracy\"].append(accuracy_score(true, candidate))\n",
        "\n",
        "# standard deviations calculations from bootstrap results\n",
        "std_devs = {label: {metric: np.std(values) for metric, values in metrics.items()} for label, metrics in bootstrap_results.items()}\n",
        "\n",
        "# original metrics calculations with standard deviations\n",
        "final_results = []\n",
        "for lab in possible_labels:\n",
        "    result = {\"Moral Value\": lab}\n",
        "    true = test_df[lab].values\n",
        "    candidate = pred_df[f\"pred_{lab}\"].values\n",
        "    \n",
        "    # Original metrics\n",
        "    result[\"F1 Score (Binary)\"] = f\"{f1_score(true, candidate, average='binary', zero_division=0):.2f} \u00b1 {std_devs[lab]['F1 (Binary)']:.2f}\"\n",
        "    result[\"F1 Score (Macro)\"] = f\"{f1_score(true, candidate, average='macro', zero_division=0):.2f} \u00b1 {std_devs[lab]['F1 (Macro)']:.2f}\"  \n",
        "    result[\"F1 Score (Weighted)\"] = f\"{f1_score(true, candidate, average='weighted', zero_division=0):.2f} \u00b1 {std_devs[lab]['F1 (Weighted)']:.2f}\"\n",
        "    \n",
        "    result[\"Precision Score (Binary)\"] = f\"{precision_score(true, candidate, average='binary', zero_division=0):.2f} \u00b1 {std_devs[lab]['Precision (Binary)']:.2f}\"\n",
        "    result[\"Precision Score (Macro)\"] = f\"{precision_score(true, candidate, average='macro', zero_division=0):.2f} \u00b1 {std_devs[lab]['Precision (Macro)']:.2f}\"    \n",
        "    result[\"Precision Score (Weighted)\"] = f\"{precision_score(true, candidate, average='weighted', zero_division=0):.2f} \u00b1 {std_devs[lab]['Precision (Weighted)']:.2f}\"\n",
        "    result[\"Recall Score (Binary)\"] = f\"{recall_score(true, candidate, average='binary', zero_division=0):.2f} \u00b1 {std_devs[lab]['Recall (Binary)']:.2f}\"\n",
        "    result[\"Recall Score (Macro)\"] = f\"{recall_score(true, candidate, average='macro', zero_division=0):.2f} \u00b1 {std_devs[lab]['Recall (Macro)']:.2f}\"\n",
        "    result[\"Recall Score (Weighted)\"] = f\"{recall_score(true, candidate, average='weighted', zero_division=0):.2f} \u00b1 {std_devs[lab]['Recall (Weighted)']:.2f}\"\n",
        "    result[\"Accuracy\"] = f\"{accuracy_score(true, candidate):.2f} \u00b1 {std_devs[lab]['Accuracy']:.2f}\"\n",
        "    \n",
        "    final_results.append(result)\n",
        "\n",
        "results_df = pd.DataFrame(final_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Moral Value</th>\n",
              "      <th>F1 Score (Binary)</th>\n",
              "      <th>F1 Score (Macro)</th>\n",
              "      <th>F1 Score (Weighted)</th>\n",
              "      <th>Precision Score (Binary)</th>\n",
              "      <th>Precision Score (Macro)</th>\n",
              "      <th>Precision Score (Weighted)</th>\n",
              "      <th>Recall Score (Binary)</th>\n",
              "      <th>Recall Score (Macro)</th>\n",
              "      <th>Recall Score (Weighted)</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>care</td>\n",
              "      <td>0.37 \u00b1 0.02</td>\n",
              "      <td>0.67 \u00b1 0.01</td>\n",
              "      <td>0.93 \u00b1 0.00</td>\n",
              "      <td>0.34 \u00b1 0.02</td>\n",
              "      <td>0.66 \u00b1 0.01</td>\n",
              "      <td>0.93 \u00b1 0.00</td>\n",
              "      <td>0.41 \u00b1 0.02</td>\n",
              "      <td>0.68 \u00b1 0.01</td>\n",
              "      <td>0.93 \u00b1 0.00</td>\n",
              "      <td>0.93 \u00b1 0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>harm</td>\n",
              "      <td>0.40 \u00b1 0.01</td>\n",
              "      <td>0.66 \u00b1 0.01</td>\n",
              "      <td>0.89 \u00b1 0.00</td>\n",
              "      <td>0.30 \u00b1 0.01</td>\n",
              "      <td>0.63 \u00b1 0.01</td>\n",
              "      <td>0.92 \u00b1 0.00</td>\n",
              "      <td>0.58 \u00b1 0.02</td>\n",
              "      <td>0.74 \u00b1 0.01</td>\n",
              "      <td>0.87 \u00b1 0.00</td>\n",
              "      <td>0.87 \u00b1 0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>fairness</td>\n",
              "      <td>0.18 \u00b1 0.01</td>\n",
              "      <td>0.56 \u00b1 0.01</td>\n",
              "      <td>0.90 \u00b1 0.00</td>\n",
              "      <td>0.13 \u00b1 0.01</td>\n",
              "      <td>0.55 \u00b1 0.00</td>\n",
              "      <td>0.93 \u00b1 0.00</td>\n",
              "      <td>0.29 \u00b1 0.02</td>\n",
              "      <td>0.60 \u00b1 0.01</td>\n",
              "      <td>0.88 \u00b1 0.00</td>\n",
              "      <td>0.88 \u00b1 0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>cheating</td>\n",
              "      <td>0.24 \u00b1 0.01</td>\n",
              "      <td>0.59 \u00b1 0.01</td>\n",
              "      <td>0.90 \u00b1 0.00</td>\n",
              "      <td>0.20 \u00b1 0.01</td>\n",
              "      <td>0.58 \u00b1 0.01</td>\n",
              "      <td>0.91 \u00b1 0.00</td>\n",
              "      <td>0.28 \u00b1 0.01</td>\n",
              "      <td>0.60 \u00b1 0.01</td>\n",
              "      <td>0.89 \u00b1 0.00</td>\n",
              "      <td>0.89 \u00b1 0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>loyalty</td>\n",
              "      <td>0.22 \u00b1 0.03</td>\n",
              "      <td>0.60 \u00b1 0.01</td>\n",
              "      <td>0.97 \u00b1 0.00</td>\n",
              "      <td>0.25 \u00b1 0.03</td>\n",
              "      <td>0.62 \u00b1 0.02</td>\n",
              "      <td>0.97 \u00b1 0.00</td>\n",
              "      <td>0.19 \u00b1 0.03</td>\n",
              "      <td>0.59 \u00b1 0.01</td>\n",
              "      <td>0.98 \u00b1 0.00</td>\n",
              "      <td>0.98 \u00b1 0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>betrayal</td>\n",
              "      <td>0.23 \u00b1 0.03</td>\n",
              "      <td>0.61 \u00b1 0.02</td>\n",
              "      <td>0.98 \u00b1 0.00</td>\n",
              "      <td>0.32 \u00b1 0.04</td>\n",
              "      <td>0.65 \u00b1 0.02</td>\n",
              "      <td>0.98 \u00b1 0.00</td>\n",
              "      <td>0.18 \u00b1 0.03</td>\n",
              "      <td>0.59 \u00b1 0.01</td>\n",
              "      <td>0.98 \u00b1 0.00</td>\n",
              "      <td>0.98 \u00b1 0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>authority</td>\n",
              "      <td>0.12 \u00b1 0.01</td>\n",
              "      <td>0.54 \u00b1 0.01</td>\n",
              "      <td>0.94 \u00b1 0.00</td>\n",
              "      <td>0.09 \u00b1 0.01</td>\n",
              "      <td>0.53 \u00b1 0.01</td>\n",
              "      <td>0.96 \u00b1 0.00</td>\n",
              "      <td>0.20 \u00b1 0.02</td>\n",
              "      <td>0.58 \u00b1 0.01</td>\n",
              "      <td>0.93 \u00b1 0.00</td>\n",
              "      <td>0.93 \u00b1 0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>subversion</td>\n",
              "      <td>0.22 \u00b1 0.02</td>\n",
              "      <td>0.60 \u00b1 0.01</td>\n",
              "      <td>0.96 \u00b1 0.00</td>\n",
              "      <td>0.21 \u00b1 0.02</td>\n",
              "      <td>0.59 \u00b1 0.01</td>\n",
              "      <td>0.96 \u00b1 0.00</td>\n",
              "      <td>0.24 \u00b1 0.02</td>\n",
              "      <td>0.61 \u00b1 0.01</td>\n",
              "      <td>0.96 \u00b1 0.00</td>\n",
              "      <td>0.96 \u00b1 0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>purity</td>\n",
              "      <td>0.13 \u00b1 0.03</td>\n",
              "      <td>0.56 \u00b1 0.01</td>\n",
              "      <td>0.99 \u00b1 0.00</td>\n",
              "      <td>0.10 \u00b1 0.02</td>\n",
              "      <td>0.55 \u00b1 0.01</td>\n",
              "      <td>0.99 \u00b1 0.00</td>\n",
              "      <td>0.19 \u00b1 0.04</td>\n",
              "      <td>0.59 \u00b1 0.02</td>\n",
              "      <td>0.98 \u00b1 0.00</td>\n",
              "      <td>0.98 \u00b1 0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>degradation</td>\n",
              "      <td>0.36 \u00b1 0.03</td>\n",
              "      <td>0.67 \u00b1 0.02</td>\n",
              "      <td>0.98 \u00b1 0.00</td>\n",
              "      <td>0.34 \u00b1 0.03</td>\n",
              "      <td>0.66 \u00b1 0.02</td>\n",
              "      <td>0.98 \u00b1 0.00</td>\n",
              "      <td>0.39 \u00b1 0.04</td>\n",
              "      <td>0.69 \u00b1 0.02</td>\n",
              "      <td>0.98 \u00b1 0.00</td>\n",
              "      <td>0.98 \u00b1 0.00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Moral Value F1 Score (Binary) F1 Score (Macro) F1 Score (Weighted)  \\\n",
              "0         care       0.37 \u00b1 0.02      0.67 \u00b1 0.01         0.93 \u00b1 0.00   \n",
              "1         harm       0.40 \u00b1 0.01      0.66 \u00b1 0.01         0.89 \u00b1 0.00   \n",
              "2     fairness       0.18 \u00b1 0.01      0.56 \u00b1 0.01         0.90 \u00b1 0.00   \n",
              "3     cheating       0.24 \u00b1 0.01      0.59 \u00b1 0.01         0.90 \u00b1 0.00   \n",
              "4      loyalty       0.22 \u00b1 0.03      0.60 \u00b1 0.01         0.97 \u00b1 0.00   \n",
              "5     betrayal       0.23 \u00b1 0.03      0.61 \u00b1 0.02         0.98 \u00b1 0.00   \n",
              "6    authority       0.12 \u00b1 0.01      0.54 \u00b1 0.01         0.94 \u00b1 0.00   \n",
              "7   subversion       0.22 \u00b1 0.02      0.60 \u00b1 0.01         0.96 \u00b1 0.00   \n",
              "8       purity       0.13 \u00b1 0.03      0.56 \u00b1 0.01         0.99 \u00b1 0.00   \n",
              "9  degradation       0.36 \u00b1 0.03      0.67 \u00b1 0.02         0.98 \u00b1 0.00   \n",
              "\n",
              "  Precision Score (Binary) Precision Score (Macro) Precision Score (Weighted)  \\\n",
              "0              0.34 \u00b1 0.02             0.66 \u00b1 0.01                0.93 \u00b1 0.00   \n",
              "1              0.30 \u00b1 0.01             0.63 \u00b1 0.01                0.92 \u00b1 0.00   \n",
              "2              0.13 \u00b1 0.01             0.55 \u00b1 0.00                0.93 \u00b1 0.00   \n",
              "3              0.20 \u00b1 0.01             0.58 \u00b1 0.01                0.91 \u00b1 0.00   \n",
              "4              0.25 \u00b1 0.03             0.62 \u00b1 0.02                0.97 \u00b1 0.00   \n",
              "5              0.32 \u00b1 0.04             0.65 \u00b1 0.02                0.98 \u00b1 0.00   \n",
              "6              0.09 \u00b1 0.01             0.53 \u00b1 0.01                0.96 \u00b1 0.00   \n",
              "7              0.21 \u00b1 0.02             0.59 \u00b1 0.01                0.96 \u00b1 0.00   \n",
              "8              0.10 \u00b1 0.02             0.55 \u00b1 0.01                0.99 \u00b1 0.00   \n",
              "9              0.34 \u00b1 0.03             0.66 \u00b1 0.02                0.98 \u00b1 0.00   \n",
              "\n",
              "  Recall Score (Binary) Recall Score (Macro) Recall Score (Weighted)  \\\n",
              "0           0.41 \u00b1 0.02          0.68 \u00b1 0.01             0.93 \u00b1 0.00   \n",
              "1           0.58 \u00b1 0.02          0.74 \u00b1 0.01             0.87 \u00b1 0.00   \n",
              "2           0.29 \u00b1 0.02          0.60 \u00b1 0.01             0.88 \u00b1 0.00   \n",
              "3           0.28 \u00b1 0.01          0.60 \u00b1 0.01             0.89 \u00b1 0.00   \n",
              "4           0.19 \u00b1 0.03          0.59 \u00b1 0.01             0.98 \u00b1 0.00   \n",
              "5           0.18 \u00b1 0.03          0.59 \u00b1 0.01             0.98 \u00b1 0.00   \n",
              "6           0.20 \u00b1 0.02          0.58 \u00b1 0.01             0.93 \u00b1 0.00   \n",
              "7           0.24 \u00b1 0.02          0.61 \u00b1 0.01             0.96 \u00b1 0.00   \n",
              "8           0.19 \u00b1 0.04          0.59 \u00b1 0.02             0.98 \u00b1 0.00   \n",
              "9           0.39 \u00b1 0.04          0.69 \u00b1 0.02             0.98 \u00b1 0.00   \n",
              "\n",
              "      Accuracy  \n",
              "0  0.93 \u00b1 0.00  \n",
              "1  0.87 \u00b1 0.00  \n",
              "2  0.88 \u00b1 0.00  \n",
              "3  0.89 \u00b1 0.00  \n",
              "4  0.98 \u00b1 0.00  \n",
              "5  0.98 \u00b1 0.00  \n",
              "6  0.93 \u00b1 0.00  \n",
              "7  0.96 \u00b1 0.00  \n",
              "8  0.98 \u00b1 0.00  \n",
              "9  0.98 \u00b1 0.00  "
            ]
          },
          "execution_count": 83,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "034414cfee08495fbe3a4aaa11d85adb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "06e8a19c0a0541b38a3648b7f149bf6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1ffb57c39aa246c0b88133f1b51ad509",
              "IPY_MODEL_7bd0123a044f491290f2ff14b6d55c36",
              "IPY_MODEL_0e026a2c581c48509a312cf9d26825d4"
            ],
            "layout": "IPY_MODEL_484668546d46495da39c648503670d73"
          }
        },
        "07d2772d747f492fb9a2aa6d4471a7d8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08d8cc4c76d44842bfb8cd45dc818895": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a33d094bd004613a959746b3e64a485": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4e23268863d743bb98393e59b6380e58",
            "placeholder": "\u200b",
            "style": "IPY_MODEL_a35ec349723c48339d025864a96e6f8a",
            "value": "\u2007466k/466k\u2007[00:00&lt;00:00,\u2007845kB/s]"
          }
        },
        "0ad7cc9a7e634b01a10fd0111a49b33c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_61c09c317cb6415784df597f2d5141ba",
            "placeholder": "\u200b",
            "style": "IPY_MODEL_2bbf119a82904e65a0f5ae427e8f7912",
            "value": "model.safetensors:\u2007100%"
          }
        },
        "0cdfc4d9b1304cce89d70f145fc946d1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e026a2c581c48509a312cf9d26825d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d2b1795a5424429fad98a2396e3eceb0",
            "placeholder": "\u200b",
            "style": "IPY_MODEL_27760a3974084c88a34b998adb2ff594",
            "value": "\u200748.0/48.0\u2007[00:00&lt;00:00,\u20072.20kB/s]"
          }
        },
        "0ee8c129824245bcb00463e0de3f14e0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1152770695604179a5a98a06c4d525e3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "125c7442d5764e58a1e14607a5031d36": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "150e3aecfff64468ad941f9d26a5705d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b75cb8d663246be9c7c4d0df5ab1b63": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ffb57c39aa246c0b88133f1b51ad509": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e1fe6ac921624ccd827a654e21972403",
            "placeholder": "\u200b",
            "style": "IPY_MODEL_034414cfee08495fbe3a4aaa11d85adb",
            "value": "tokenizer_config.json:\u2007100%"
          }
        },
        "2488e56d59cd4b8e832759c857b93c62": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "24b9bf9278454be0983b3b8b0435fbaa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5866daa3bd82413c894ed224c3ef3f6f",
            "placeholder": "\u200b",
            "style": "IPY_MODEL_c86af84480944045985b99462a57f8fc",
            "value": "tokenizer.json:\u2007100%"
          }
        },
        "27760a3974084c88a34b998adb2ff594": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "277ae2506ba9481c8155f230b5ce4290": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2bbf119a82904e65a0f5ae427e8f7912": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2f6f18fa379e49eea37d8e9cfafc7d91": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3382b5eb779f4007b2bac46ff84d1dc2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4130519be716408d8930a866ba1473b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "484668546d46495da39c648503670d73": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48638f669d034b85922626738d696a18": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ba5ad85660d04485b4a6ca61dc034330",
              "IPY_MODEL_af987ceddcc141a2a89c93127a11f6be",
              "IPY_MODEL_9cebcddef88540bd8acb11eabf6601bf"
            ],
            "layout": "IPY_MODEL_0ee8c129824245bcb00463e0de3f14e0"
          }
        },
        "4cdb28ad2e9545a189e100ca02d02205": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9c94fcb097734364b54dfede72d735f8",
              "IPY_MODEL_9944266adc3940728af07f08dd17c311",
              "IPY_MODEL_855ff82945b2419ab7c7672ef2211716"
            ],
            "layout": "IPY_MODEL_849880be758c44378637ec6925d98dec"
          }
        },
        "4e23268863d743bb98393e59b6380e58": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5866daa3bd82413c894ed224c3ef3f6f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e101b3f726943ac834d8856e69b51ae": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61c09c317cb6415784df597f2d5141ba": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "783bef901aa947a89bab37cf8a874a03": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "79e5574bf6914854956a1e3ab9d0dd91": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7bd0123a044f491290f2ff14b6d55c36": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c7b312d1e3514b9d977c6385fe214c4b",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c8728d5c11c14342afd8babef02ab4ba",
            "value": 48
          }
        },
        "849880be758c44378637ec6925d98dec": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "855ff82945b2419ab7c7672ef2211716": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0cdfc4d9b1304cce89d70f145fc946d1",
            "placeholder": "\u200b",
            "style": "IPY_MODEL_2488e56d59cd4b8e832759c857b93c62",
            "value": "\u20070/5\u2007[00:00&lt;?,\u2007?it/s]"
          }
        },
        "86df6fbea7ba457c98830f1fff5e04c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e101b3f726943ac834d8856e69b51ae",
            "placeholder": "\u200b",
            "style": "IPY_MODEL_90c632921e7547e0a98e579a66b196f0",
            "value": "\u2007570/570\u2007[00:00&lt;00:00,\u200730.7kB/s]"
          }
        },
        "8c3a4c94c7b8433f890b783649d6e867": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_24b9bf9278454be0983b3b8b0435fbaa",
              "IPY_MODEL_cb722da43b9d4b709869d727e71cb32d",
              "IPY_MODEL_0a33d094bd004613a959746b3e64a485"
            ],
            "layout": "IPY_MODEL_91ed12b162a94125ae8e49d3ed7a4b5f"
          }
        },
        "8f72250de51240ba836884b80fd6b9f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "90c632921e7547e0a98e579a66b196f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "90d556daac7447d8a720aec7718aa393": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd46c89cebbf4948ab97a6369cbb571f",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4130519be716408d8930a866ba1473b3",
            "value": 570
          }
        },
        "91ed12b162a94125ae8e49d3ed7a4b5f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9944266adc3940728af07f08dd17c311": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_07d2772d747f492fb9a2aa6d4471a7d8",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_125c7442d5764e58a1e14607a5031d36",
            "value": 0
          }
        },
        "9c94fcb097734364b54dfede72d735f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c1e0037bafef481b844db983d59af3a5",
            "placeholder": "\u200b",
            "style": "IPY_MODEL_c931130302454bf3bc2623d388ac4560",
            "value": "Epoch:\u2007\u2007\u20070%"
          }
        },
        "9cebcddef88540bd8acb11eabf6601bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1152770695604179a5a98a06c4d525e3",
            "placeholder": "\u200b",
            "style": "IPY_MODEL_277ae2506ba9481c8155f230b5ce4290",
            "value": "\u2007232k/232k\u2007[00:00&lt;00:00,\u2007615kB/s]"
          }
        },
        "a35ec349723c48339d025864a96e6f8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a5db698c14874c2c8e0b501286f674fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0ad7cc9a7e634b01a10fd0111a49b33c",
              "IPY_MODEL_fd148bc24e57454b83dc07dc7c3a560a",
              "IPY_MODEL_f1cb53890867466c893b89b2232fead0"
            ],
            "layout": "IPY_MODEL_b3973cdc12d04893a69ecfffe7b06353"
          }
        },
        "adae4e8339184e888a93f6a28e0494a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "af987ceddcc141a2a89c93127a11f6be": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b75cb8d663246be9c7c4d0df5ab1b63",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_783bef901aa947a89bab37cf8a874a03",
            "value": 231508
          }
        },
        "b3973cdc12d04893a69ecfffe7b06353": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba5ad85660d04485b4a6ca61dc034330": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_79e5574bf6914854956a1e3ab9d0dd91",
            "placeholder": "\u200b",
            "style": "IPY_MODEL_8f72250de51240ba836884b80fd6b9f5",
            "value": "vocab.txt:\u2007100%"
          }
        },
        "bcf6e4df9bc547aaa50729d6928e1ec6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf1030a82a4f4536b0887f837ed2a7e3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1e0037bafef481b844db983d59af3a5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7b312d1e3514b9d977c6385fe214c4b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c86af84480944045985b99462a57f8fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c8728d5c11c14342afd8babef02ab4ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c931130302454bf3bc2623d388ac4560": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cb722da43b9d4b709869d727e71cb32d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf1030a82a4f4536b0887f837ed2a7e3",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2f6f18fa379e49eea37d8e9cfafc7d91",
            "value": 466062
          }
        },
        "cd28fc4d177b4abbbc84d985220322d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_efea0bb741f7448baf6d847f5a566ae6",
              "IPY_MODEL_90d556daac7447d8a720aec7718aa393",
              "IPY_MODEL_86df6fbea7ba457c98830f1fff5e04c2"
            ],
            "layout": "IPY_MODEL_3382b5eb779f4007b2bac46ff84d1dc2"
          }
        },
        "d2b1795a5424429fad98a2396e3eceb0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df64a6dcf7f445bd82f044a88a2f8313": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e1fe6ac921624ccd827a654e21972403": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "efea0bb741f7448baf6d847f5a566ae6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_150e3aecfff64468ad941f9d26a5705d",
            "placeholder": "\u200b",
            "style": "IPY_MODEL_adae4e8339184e888a93f6a28e0494a3",
            "value": "config.json:\u2007100%"
          }
        },
        "f1cb53890867466c893b89b2232fead0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_08d8cc4c76d44842bfb8cd45dc818895",
            "placeholder": "\u200b",
            "style": "IPY_MODEL_f412088be212468e9f4db1cb6b48c03c",
            "value": "\u2007440M/440M\u2007[00:06&lt;00:00,\u200795.5MB/s]"
          }
        },
        "f412088be212468e9f4db1cb6b48c03c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fd148bc24e57454b83dc07dc7c3a560a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bcf6e4df9bc547aaa50729d6928e1ec6",
            "max": 440449768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_df64a6dcf7f445bd82f044a88a2f8313",
            "value": 440449768
          }
        },
        "fd46c89cebbf4948ab97a6369cbb571f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "state": {}
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}